{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Problem definition","metadata":{}},{"cell_type":"markdown","source":"**Problem Definition:**\n\n* It is a binary classification problem based on the graph data.\n* The task is to predict the anticancer activity of a chemical compound using the chemical structure of the compound.\n\nThe chemical compound can be positive or negative against lung cancer cell and thus labelled as either 0 or 1.\n\n**Define the data input and output:-**\n\n* The data is in the form of graph which represents the chemical structure of the compound.\n* Each sample of data contains information about the atoms and the connections between atoms of the molecule.\n* So in this problem the features are the atoms and connections.\n* The input file is structure data file (SDF). It contains information about the chemical composition of a molecule. SDF file store information about position of individual atom in the chemical compound and also tells about the connections.\n\n**What is the experimental protocol used and how was it carried out?**\n\n* The first step is to read the sdf file to get the information about the atoms and their connectivity in the compound. The atoms are described as nodes and connections are described as edges. The read_sdf method is used to read sdf file and the chemical composition of the compound.\n\n* The nodes are given as characters. Thus it is treated as sequence of text data and best way to describe the text data sequence to tokenize the data and then adding the embeddig layer.\n\n* Graph convolutional network is used to calculate the probability of the output class. Different methods differ in implementing message passing methods.\n\n**What could be the challenges?** \n\nDeveloping a successful solution to our problem , complex data,datasets can include complex data elements ,another thing is that we have to make sure that our algorithm must be efficient and scalable to extract information from the big data and we should have enough knowledge and experience in order to use them if we needed to improve our algorithms.\n\n**What data mining function is required?**\n\nTokenization when it comes to preprocessing in order to tokenize the data before adding the embeddig layer.\n\n**What is the impact?**\n\nIt will make a great impact when it comes to medical field as it is going to predict wether chemical compunds are positive or negative in terms of lung cancer resistence\n\n**What is an ideal solution?**\n\nAn ideal solution in my opinion will be measured in terms of metrics and performances\n","metadata":{}},{"cell_type":"code","source":"!pip install --quiet networkx\n!pip install --quiet tf2_gnn","metadata":{"execution":{"iopub.status.busy":"2023-04-28T23:34:42.799071Z","iopub.execute_input":"2023-04-28T23:34:42.799694Z","iopub.status.idle":"2023-04-28T23:35:07.481943Z","shell.execute_reply.started":"2023-04-28T23:34:42.799654Z","shell.execute_reply":"2023-04-28T23:35:07.480503Z"},"trusted":true},"execution_count":92,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"#importing libraries\nimport numpy as np   \nfrom tqdm.notebook import tqdm\n\nfrom sklearn.model_selection import train_test_split\n\n#importing libraries for displaying network of molecule\n\nimport networkx as nx\nimport matplotlib.pyplot as plt\nfrom matplotlib import cm\n\n#libraries for text preprocessing\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nimport random\n\n#for deep Graph Neural Network\nfrom tf2_gnn.layers.gnn import GNN, GNNInput\nfrom  tf2_gnn.layers.message_passing import rgat,rgin,rgcn,gnn_film,ggnn,gnn_edge_mlp\nfrom  tf2_gnn.layers.message_passing import RGAT,  MessagePassing, MessagePassingInput\n\n#importing tensorflow and other libraries\nimport tensorflow as tf\nfrom tensorflow.math import segment_mean #to calculate segmented mean\nfrom tensorflow import keras\nfrom tensorflow.keras import Input, Model #layers and model\nfrom tensorflow.keras.layers import Embedding, Dense, Dropout #layers\nfrom tensorflow.keras.optimizers import Adam #optimizer\n\nimport math\nimport pandas as pd \n%matplotlib inline\nimport seaborn as sns\n#Set aesthetic parameters in one step.\nsns.set()","metadata":{"execution":{"iopub.status.busy":"2023-04-28T23:54:05.585954Z","iopub.execute_input":"2023-04-28T23:54:05.586523Z","iopub.status.idle":"2023-04-28T23:54:05.608562Z","shell.execute_reply.started":"2023-04-28T23:54:05.586474Z","shell.execute_reply":"2023-04-28T23:54:05.607188Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom tqdm.notebook import tqdm\n\ndef read_sdf(file):\n    with open(file, 'r') as rf:\n        content = rf.read()\n        #split each sample alone by ($$$$)\n    samples = content.split('$$$$')\n    \n    def parse_sample(s):\n        lines = s.splitlines()\n        links = []\n        nodes = []\n        label = 0\n        #if the label : ==1 leave it as it is, if ==-1 make it 0.\n        for l in lines:\n            if l.strip() == '1.0':\n                label = 1\n            if l.strip() == '-1.0':\n                label = 0\n            if l.startswith('    '):\n                feature = l.split()\n                node = feature[3]\n                nodes.append(node)\n            elif l.startswith(' '):\n                lnk = l.split()\n                # edge: (from, to,) (1-based index)\n                #edge represent link between each two nodes\n                if int(lnk[0]) - 1 < len(nodes):\n                    links.append((\n                        int(lnk[0])-1, \n                        int(lnk[1])-1, # zero-based index\n                        # int(lnk[2]) ignore edge weight\n                    ))\n        return nodes, np.array(links), label\n    \n    return [parse_sample(s) for s in tqdm(samples) if len(s[0]) > 0]","metadata":{"execution":{"iopub.status.busy":"2023-04-28T23:54:05.868291Z","iopub.execute_input":"2023-04-28T23:54:05.868783Z","iopub.status.idle":"2023-04-28T23:54:05.882133Z","shell.execute_reply.started":"2023-04-28T23:54:05.868741Z","shell.execute_reply":"2023-04-28T23:54:05.880922Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"code","source":"#reading train.sdf file\ntraining_set = read_sdf('/kaggle/input/cisc873-dm-w23-a6/train.sdf')\n\n#splitting the train data\ntraining_set, validation_set = train_test_split(training_set, test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T23:54:06.586387Z","iopub.execute_input":"2023-04-28T23:54:06.587189Z","iopub.status.idle":"2023-04-28T23:54:09.587683Z","shell.execute_reply.started":"2023-04-28T23:54:06.587137Z","shell.execute_reply":"2023-04-28T23:54:09.586282Z"},"trusted":true},"execution_count":95,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/25024 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80998859d6484a2cbbdcd96a9b812abb"}},"metadata":{}}]},{"cell_type":"code","source":"\n#reading test file\ntesting_set = read_sdf('/kaggle/input/cisc873-dm-w23-a6/test_x.sdf')","metadata":{"execution":{"iopub.status.busy":"2023-04-28T23:54:11.784021Z","iopub.execute_input":"2023-04-28T23:54:11.784505Z","iopub.status.idle":"2023-04-28T23:54:16.019124Z","shell.execute_reply.started":"2023-04-28T23:54:11.784468Z","shell.execute_reply":"2023-04-28T23:54:16.017753Z"},"trusted":true},"execution_count":96,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/12326 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34e370ec1e0d421988d12479a9fcc511"}},"metadata":{}}]},{"cell_type":"markdown","source":"# Visualizing/Inspecting a Sample","metadata":{}},{"cell_type":"code","source":"colors = cm.rainbow(np.linspace(0, 1, 50))\n\ndef visualize(sample):\n  #initiating an instance of Graph\n  G=nx.Graph()\n  #all atoms as nodes\n  nodes = sample[0]\n  #all connections as edges\n  edges = sample[1]\n  #empty dictionary for labels for the all nodes\n  labeldict={}\n  #empty array for each node color\n  node_color=[]\n  for i,n in enumerate(nodes):\n    #adding node to the graph each node as (0,1,2,3..)\n    G.add_node(i)\n    #dictionary building with [key,value] as [0:'C']\n    labeldict[i]=n\n    #color coding\n    node_color.append(colors[hash(n)%len(colors)])\n\n  # a list of nodes:\n  for e in edges:\n    #adding egde to the graph from one connection to other connection\n    G.add_edge(e[0], e[1]) \n\n  #drawing the graph with labels for nodes as atoms and connections as edges    \n  nx.draw(G, labels=labeldict, with_labels = True, node_color = node_color)\n  #draw the graph\n  plt.show()\n  #returns graph\n  return G","metadata":{"execution":{"iopub.status.busy":"2023-04-28T23:54:33.885738Z","iopub.execute_input":"2023-04-28T23:54:33.887365Z","iopub.status.idle":"2023-04-28T23:54:33.897288Z","shell.execute_reply.started":"2023-04-28T23:54:33.887304Z","shell.execute_reply":"2023-04-28T23:54:33.896075Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"#displaying one sample\nplt.clf()\nvisualize(training_set[5])","metadata":{"execution":{"iopub.status.busy":"2023-04-28T23:54:40.498662Z","iopub.execute_input":"2023-04-28T23:54:40.499085Z","iopub.status.idle":"2023-04-28T23:54:40.716031Z","shell.execute_reply.started":"2023-04-28T23:54:40.499050Z","shell.execute_reply":"2023-04-28T23:54:40.714620Z"},"trusted":true},"execution_count":98,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"execution_count":98,"output_type":"execute_result","data":{"text/plain":"<networkx.classes.graph.Graph at 0x72824b20c210>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"#vocabulary size\nmax_vocab = 500\n# maximum length of the tokenized vector\nmax_len = 100 \n\n# build vocabulary from training set only for nodes characters\nall_nodes = [s[0] for s in training_set]\n\n#training tokenizer\ntokenizer = Tokenizer(num_words = max_vocab)\ntokenizer.fit_on_texts(all_nodes)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T23:54:43.160426Z","iopub.execute_input":"2023-04-28T23:54:43.160855Z","iopub.status.idle":"2023-04-28T23:54:43.453749Z","shell.execute_reply.started":"2023-04-28T23:54:43.160817Z","shell.execute_reply":"2023-04-28T23:54:43.452511Z"},"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"code","source":"random.seed(0)\n\ndef prepare_single_batch(samples):\n  #nodes characters array\n  sample_nodes = [s[0] for s in samples]\n  #tokenizing the sample nodes\n  sample_nodes = tokenizer.texts_to_sequences(sample_nodes)\n  #pad_sequences for each sample node with post padding and post truncating \n  sample_nodes = pad_sequences(sample_nodes, padding='post', truncating = 'pre')\n  #maximum length of nodes \n  max_nodes_len = np.shape(sample_nodes)[1]\n  #defining edges\n  edges = [s[1]+i*max_nodes_len for i,s in enumerate(samples)]\n  edges = [e for e in edges if len(e) > 0]\n\n  #array definition for segmented_ids\n  node_to_graph = [[i]*max_nodes_len for i in range(len(samples))]\n  \n  #reshaping as 1 vector\n  all_nodes = np.reshape(sample_nodes, -1)\n  #concatenating all the edges as size [total_edges ,2]\n  all_edges = np.concatenate(edges)\n\n  node_to_graph = np.reshape(node_to_graph, -1)\n  #returns a dictionary of features(data,edges,node2grah) and label\n  return {\n      'data': all_nodes,\n      'edges': all_edges,\n      'node2grah': node_to_graph,\n  }, np.array([s[2] for s in samples]) ","metadata":{"execution":{"iopub.status.busy":"2023-04-28T23:54:43.918453Z","iopub.execute_input":"2023-04-28T23:54:43.918852Z","iopub.status.idle":"2023-04-28T23:54:43.929905Z","shell.execute_reply.started":"2023-04-28T23:54:43.918819Z","shell.execute_reply":"2023-04-28T23:54:43.928333Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"code","source":"def gen_batch(dataset, batch_size=16, repeat=False, shuffle=True):\n    while True:\n      dataset = list(dataset)\n      if shuffle:\n        #randomly shuffling\n        random.shuffle(dataset)\n      \n      #length of dataset\n      l = len(dataset)\n      #for creating batches from given dataset\n      for ndx in range(0, l, batch_size):\n        #creating batch samples with given batch_size\n        batch_samples = dataset[ndx:min(ndx + batch_size, l)]\n        #returning a generator with prepared batches\n        yield prepare_single_batch(batch_samples)\n        \n      if not repeat:\n          break","metadata":{"execution":{"iopub.status.busy":"2023-04-28T23:54:47.039240Z","iopub.execute_input":"2023-04-28T23:54:47.040261Z","iopub.status.idle":"2023-04-28T23:54:47.048314Z","shell.execute_reply.started":"2023-04-28T23:54:47.040208Z","shell.execute_reply":"2023-04-28T23:54:47.047248Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"\n# showing one batch:\nfor train_batch in gen_batch(training_set, batch_size=4):\n    for k,v in train_batch[0].items():\n        print(k)        \n        print(\"Shape is \"+str(np.shape(v)))\n        pass\n    print('label', train_batch[1])\n    break","metadata":{"execution":{"iopub.status.busy":"2023-04-28T23:54:52.790548Z","iopub.execute_input":"2023-04-28T23:54:52.791386Z","iopub.status.idle":"2023-04-28T23:54:52.818860Z","shell.execute_reply.started":"2023-04-28T23:54:52.791343Z","shell.execute_reply":"2023-04-28T23:54:52.817534Z"},"trusted":true},"execution_count":102,"outputs":[{"name":"stdout","text":"data\nShape is (200,)\nedges\nShape is (133, 2)\nnode2grah\nShape is (200,)\nlabel [0 0 0 0]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# build the model architecture","metadata":{}},{"cell_type":"markdown","source":"# **Trail_1**","metadata":{}},{"cell_type":"code","source":"#Input layer for nodes (tokenized text data)\ndata = keras.Input(batch_shape=(None,))\n\n# the first dim is different to the previous one. it is the total number of edges in this batch\n\n#Input layer for edge data\nedge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n#Input layer for node2graph ids\nnode2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n#embedding layer over data with each token embedded as a vector\nembeded = Embedding(tokenizer.num_words, 80)(data)\n\n\n# number of graphs (number of samples)\n#calculating number of samples (or min(batch_size,no._of_samples))\nnum_graph = tf.reduce_max(node2graph)+1  \n\n#gnn_input layer with inputs as defined above\ngnn_input = GNNInput(\n    node_features=embeded,\n    adjacency_lists=(edge,),\n    node_to_graph_map=node2graph, \n    num_graphs=num_graph,\n)\n\n#defining hyperparameters for GNN layer\nparams = GNN.get_default_hyperparameters()\n#defining hidden dimension of the gnn layer is 32\nparams[\"hidden_dim\"] = 32\n#gnn layer with defined hyperparameters\ngnn_layer = GNN(params)  \n#gnn output layer \n#outpur shape: [data_dimension,hidden layers]\ngnn_out = gnn_layer(gnn_input) \n\nprint('gnn_out', gnn_out)           \n\n#calculating segmented mean based on segment_ids\navg = segment_mean(\n    data=gnn_out,\n    segment_ids=node2graph\n    )\n\nprint('mean:', avg)\n\n#final dense layer with sigmoid\npred = Dense(1, activation='sigmoid')(avg)\n#output shape: [batch_size,1]\nprint('pred:', pred)\n\n#Building The Model \n#inputs is dictionary of data, edges, node2graph\n#output: prediction value from dense layer\nmodel = Model(\n    inputs={\n        'data': data, \n        'edges': edge,\n        'node2grah': node2graph,\n    },\n    outputs=pred\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-26T17:35:19.456268Z","iopub.execute_input":"2023-04-26T17:35:19.457508Z","iopub.status.idle":"2023-04-26T17:35:22.302051Z","shell.execute_reply.started":"2023-04-26T17:35:19.457452Z","shell.execute_reply":"2023-04-26T17:35:22.300636Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='gnn_1/StatefulPartitionedCall:0', description=\"created by layer 'gnn_1'\")\nmean: KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='tf.math.segment_mean_1/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_1'\")\npred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense/Sigmoid:0', description=\"created by layer 'dense'\")\n","output_type":"stream"}]},{"cell_type":"code","source":"\n#printing summary of the model\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-26T17:35:22.304177Z","iopub.execute_input":"2023-04-26T17:35:22.304556Z","iopub.status.idle":"2023-04-26T17:35:22.354314Z","shell.execute_reply.started":"2023-04-26T17:35:22.304518Z","shell.execute_reply":"2023-04-26T17:35:22.352987Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_12 (InputLayer)          [(None,)]            0           []                               \n                                                                                                  \n input_10 (InputLayer)          [(None,)]            0           []                               \n                                                                                                  \n tf.math.reduce_max_1 (TFOpLamb  ()                  0           ['input_12[0][0]']               \n da)                                                                                              \n                                                                                                  \n embedding_2 (Embedding)        (None, 80)           40000       ['input_10[0][0]']               \n                                                                                                  \n input_11 (InputLayer)          [(None, 2)]          0           []                               \n                                                                                                  \n tf.__operators__.add_1 (TFOpLa  ()                  0           ['tf.math.reduce_max_1[0][0]']   \n mbda)                                                                                            \n                                                                                                  \n gnn_1 (GNN)                    (None, 32)           24384       ['embedding_2[0][0]',            \n                                                                  'input_11[0][0]',               \n                                                                  'input_12[0][0]',               \n                                                                  'tf.__operators__.add_1[0][0]'] \n                                                                                                  \n tf.math.segment_mean_1 (TFOpLa  (None, 32)          0           ['gnn_1[0][0]',                  \n mbda)                                                            'input_12[0][0]']               \n                                                                                                  \n dense (Dense)                  (None, 1)            33          ['tf.math.segment_mean_1[0][0]'] \n                                                                                                  \n==================================================================================================\nTotal params: 64,417\nTrainable params: 64,417\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"#I will create Adam Optimizer for training optimizer with this hyperparameters\nad = tf.keras.optimizers.Adam(\n    learning_rate=0.001,\n    beta_1=0.9,\n    beta_2=0.999,\n    epsilon=1e-07,\n    amsgrad=False,\n    name=\"Adam\"\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-26T13:54:41.127651Z","iopub.execute_input":"2023-04-26T13:54:41.128123Z","iopub.status.idle":"2023-04-26T13:54:41.137581Z","shell.execute_reply.started":"2023-04-26T13:54:41.128078Z","shell.execute_reply":"2023-04-26T13:54:41.136257Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"#compile the model by using my adam optimizer and BinaryCrossentropy loss\nmodel.compile(\n    optimizer = ad,\n    loss='BinaryCrossentropy',\n    metrics=['AUC']\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-26T13:54:51.117892Z","iopub.execute_input":"2023-04-26T13:54:51.119125Z","iopub.status.idle":"2023-04-26T13:54:51.130921Z","shell.execute_reply.started":"2023-04-26T13:54:51.119074Z","shell.execute_reply":"2023-04-26T13:54:51.129920Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"%%time\nbatch_size = 32\n#math.ceil: returns the smallest integral value greater than the number\n#no. of batches for training data\nnum_batchs = math.ceil(len(training_set) / batch_size)\n#no. of batches for validation data\nnum_batchs_validation = math.ceil(len(validation_set) / batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-04-26T13:55:11.300670Z","iopub.execute_input":"2023-04-26T13:55:11.301138Z","iopub.status.idle":"2023-04-26T13:55:11.308036Z","shell.execute_reply.started":"2023-04-26T13:55:11.301096Z","shell.execute_reply":"2023-04-26T13:55:11.306831Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"CPU times: user 11 s, sys: 0 ns, total: 11 s\nWall time: 16 s\n","output_type":"stream"}]},{"cell_type":"code","source":"#fit the models with 30 epoch and no early stopping\nhist = model.fit(\n    gen_batch(\n        training_set, batch_size=batch_size, repeat=True\n    ),\n    steps_per_epoch=num_batchs,\n    epochs=30,\n    validation_data=gen_batch(\n        validation_set, batch_size=32, repeat=True\n    ),\n    validation_steps=num_batchs_validation,\n    verbose=1\n)\nprint(hist)","metadata":{"execution":{"iopub.status.busy":"2023-04-26T13:55:25.775657Z","iopub.execute_input":"2023-04-26T13:55:25.776156Z","iopub.status.idle":"2023-04-26T14:03:51.120541Z","shell.execute_reply.started":"2023-04-26T13:55:25.776112Z","shell.execute_reply":"2023-04-26T14:03:51.119057Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"Epoch 1/30\n626/626 [==============================] - 18s 24ms/step - loss: 0.2692 - auc: 0.4262 - val_loss: 0.2110 - val_auc: 0.5067\nEpoch 2/30\n626/626 [==============================] - 15s 23ms/step - loss: 0.2018 - auc: 0.5520 - val_loss: 0.1974 - val_auc: 0.5906\nEpoch 3/30\n626/626 [==============================] - 15s 23ms/step - loss: 0.1926 - auc: 0.6077 - val_loss: 0.1938 - val_auc: 0.6626\nEpoch 4/30\n626/626 [==============================] - 15s 24ms/step - loss: 0.1858 - auc: 0.6641 - val_loss: 0.1929 - val_auc: 0.6192\nEpoch 5/30\n626/626 [==============================] - 15s 23ms/step - loss: 0.1820 - auc: 0.6861 - val_loss: 0.1846 - val_auc: 0.7158\nEpoch 6/30\n626/626 [==============================] - 15s 24ms/step - loss: 0.1807 - auc: 0.6925 - val_loss: 0.1810 - val_auc: 0.7144\nEpoch 7/30\n626/626 [==============================] - 14s 23ms/step - loss: 0.1804 - auc: 0.6888 - val_loss: 0.1826 - val_auc: 0.7010\nEpoch 8/30\n626/626 [==============================] - 15s 24ms/step - loss: 0.1780 - auc: 0.7036 - val_loss: 0.1853 - val_auc: 0.7368\nEpoch 9/30\n626/626 [==============================] - 14s 23ms/step - loss: 0.1771 - auc: 0.7209 - val_loss: 0.1776 - val_auc: 0.7442\nEpoch 10/30\n626/626 [==============================] - 15s 24ms/step - loss: 0.1745 - auc: 0.7259 - val_loss: 0.1760 - val_auc: 0.7476\nEpoch 11/30\n626/626 [==============================] - 15s 23ms/step - loss: 0.1737 - auc: 0.7352 - val_loss: 0.1781 - val_auc: 0.7440\nEpoch 12/30\n626/626 [==============================] - 16s 25ms/step - loss: 0.1715 - auc: 0.7493 - val_loss: 0.1754 - val_auc: 0.7490\nEpoch 13/30\n626/626 [==============================] - 14s 23ms/step - loss: 0.1707 - auc: 0.7535 - val_loss: 0.1711 - val_auc: 0.7563\nEpoch 14/30\n626/626 [==============================] - 15s 23ms/step - loss: 0.1701 - auc: 0.7509 - val_loss: 0.1801 - val_auc: 0.7491\nEpoch 15/30\n626/626 [==============================] - 15s 23ms/step - loss: 0.1695 - auc: 0.7568 - val_loss: 0.1735 - val_auc: 0.7583\nEpoch 16/30\n626/626 [==============================] - 14s 23ms/step - loss: 0.1691 - auc: 0.7629 - val_loss: 0.1787 - val_auc: 0.7534\nEpoch 17/30\n626/626 [==============================] - 15s 23ms/step - loss: 0.1683 - auc: 0.7627 - val_loss: 0.1717 - val_auc: 0.7591\nEpoch 18/30\n626/626 [==============================] - 14s 23ms/step - loss: 0.1678 - auc: 0.7692 - val_loss: 0.1758 - val_auc: 0.7537\nEpoch 19/30\n626/626 [==============================] - 15s 24ms/step - loss: 0.1671 - auc: 0.7726 - val_loss: 0.1851 - val_auc: 0.7643\nEpoch 20/30\n626/626 [==============================] - 15s 23ms/step - loss: 0.1664 - auc: 0.7740 - val_loss: 0.1697 - val_auc: 0.7638\nEpoch 21/30\n626/626 [==============================] - 15s 24ms/step - loss: 0.1673 - auc: 0.7751 - val_loss: 0.1784 - val_auc: 0.7782\nEpoch 22/30\n626/626 [==============================] - 15s 24ms/step - loss: 0.1650 - auc: 0.7851 - val_loss: 0.1719 - val_auc: 0.7704\nEpoch 23/30\n626/626 [==============================] - 15s 24ms/step - loss: 0.1654 - auc: 0.7841 - val_loss: 0.1723 - val_auc: 0.7769\nEpoch 24/30\n626/626 [==============================] - 15s 24ms/step - loss: 0.1645 - auc: 0.7866 - val_loss: 0.1716 - val_auc: 0.7764\nEpoch 25/30\n626/626 [==============================] - 15s 24ms/step - loss: 0.1649 - auc: 0.7877 - val_loss: 0.1795 - val_auc: 0.7614\nEpoch 26/30\n626/626 [==============================] - 15s 24ms/step - loss: 0.1643 - auc: 0.7899 - val_loss: 0.1770 - val_auc: 0.7972\nEpoch 27/30\n626/626 [==============================] - 15s 24ms/step - loss: 0.1618 - auc: 0.7984 - val_loss: 0.1709 - val_auc: 0.7711\nEpoch 28/30\n626/626 [==============================] - 15s 23ms/step - loss: 0.1636 - auc: 0.7932 - val_loss: 0.1784 - val_auc: 0.7752\nEpoch 29/30\n626/626 [==============================] - 15s 24ms/step - loss: 0.1617 - auc: 0.7988 - val_loss: 0.1689 - val_auc: 0.7755\nEpoch 30/30\n626/626 [==============================] - 15s 24ms/step - loss: 0.1610 - auc: 0.8034 - val_loss: 0.1773 - val_auc: 0.7922\n<keras.callbacks.History object at 0x7c02f1432110>\n","output_type":"stream"}]},{"cell_type":"code","source":"\n#make a prediction by using the model\ny_pred = model.predict(\n    gen_batch(testing_set, batch_size=16, shuffle=False)\n)\ny_pred = np.reshape(y_pred, -1)","metadata":{"execution":{"iopub.status.busy":"2023-04-26T14:03:51.123040Z","iopub.execute_input":"2023-04-26T14:03:51.123628Z","iopub.status.idle":"2023-04-26T14:03:56.555480Z","shell.execute_reply.started":"2023-04-26T14:03:51.123575Z","shell.execute_reply":"2023-04-26T14:03:56.554503Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"771/771 [==============================] - 4s 5ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"#make a submission file to upload it on kaggle\nsubmission = pd.DataFrame({'label':y_pred})\nsubmission.index.name = 'id'\nsubmission.to_csv('Trial_2.csv')\n\n#0.81299","metadata":{"execution":{"iopub.status.busy":"2023-04-26T14:04:09.245739Z","iopub.execute_input":"2023-04-26T14:04:09.246159Z","iopub.status.idle":"2023-04-26T14:04:09.289289Z","shell.execute_reply.started":"2023-04-26T14:04:09.246121Z","shell.execute_reply":"2023-04-26T14:04:09.287885Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":"**Expectation:**\n\nThis code defines a GNN (Graph Neural Network) model that takes in tokenized text data and predicts a binary classification label. The model has an input layer for the tokenized text data, an input layer for the edge data, and an input layer for the node-to-graph mapping. The tokenized text data is first embedded using an embedding layer, and then passed through a GNN layer. The output of the GNN layer is then passed through a dense layer with a sigmoid activation function to obtain the binary classification label.","metadata":{}},{"cell_type":"markdown","source":"**Observation:**\nThe code defines the input layers and sets the batch size for each input. It then creates an embedding layer to embed the tokenized text data. Next, it creates a GNNInput layer with the embedded data, the edge data, and the node-to-graph mapping. The GNNInput layer is passed through a GNN layer with hyperparameters defined by the params dictionary. Finally, the output of the GNN layer is passed through a dense layer with a sigmoid activation function to obtain the binary classification label.","metadata":{}},{"cell_type":"markdown","source":"**plan**\n\nI will change my hyperparameters to :\n\nparams[\"hidden_dim\"] = 32 \nparams[\"message_calculation_class\"] = 'GGNN'","metadata":{}},{"cell_type":"markdown","source":"# Trial_2 (GGNN)","metadata":{}},{"cell_type":"code","source":"#Input layer for nodes (tokenized text data)\ndata = keras.Input(batch_shape=(None,))\n\n# the first dim is different to the previous one. it is the total number of edges in this batch\n#Input layer for edge data\nedge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n#Input layer for node2graph ids\nnode2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n\n#embedding layer over data with each token embedded as a vector   size vector eg. [440,75]\nembeded = Embedding(tokenizer.num_words, 75)(data)\n\n# number of graphs (number of samples)\n#calculating number of samples (or min(batch_size,no._of_samples))\nnum_graph = tf.reduce_max(node2graph)+1  \n\n#gnn_input layer with inputs as defined above\ngnn_input = GNNInput(\n    node_features=embeded,\n    adjacency_lists=(edge,),\n    node_to_graph_map=node2graph, \n    num_graphs=num_graph,\n)\n\n#defining hyperparameters for GNN layer\nparams = GNN.get_default_hyperparameters()\n#defining hidden dimension of the gnn layer\nparams[\"hidden_dim\"] = 32 \nparams[\"message_calculation_class\"] = 'GGNN'\n#params[\"num_edge_MLP_hidden_layers\"] = 16\n\n#gnn layer with defined hyperparameters\ngnn_layer = GNN(params) \n\n#gnn output layer\n#outpur shape: [data_dimension,hidden layers]\ngnn_out = gnn_layer(gnn_input)\n\nprint('gnn_out', gnn_out)           \n\n#calculating segmented mean based on segment_ids\navg = segment_mean(\n    data=gnn_out,\n    segment_ids=node2graph\n    )\n\nprint('mean:', avg)\n\n#final dense layer with sigmoid\n#Output [None,8]\nfc1 = Dense(8,activation='relu')(avg)\n#fc2 = Dense(64,activation='relu')(fc1)\n\n#output shape: [batch_size,1] \npred = Dense(1, activation='sigmoid')(fc1)\nprint('pred:', pred)\n\n#Building The Model \n#inputs is dictionary of data, edges, node2graph\n#output: prediction value from dense layer\nmodel_2 = Model(\n    inputs={\n        'data': data, \n        'edges': edge,\n        'node2grah': node2graph,\n    },\n    outputs=pred\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T23:55:06.072858Z","iopub.execute_input":"2023-04-28T23:55:06.073376Z","iopub.status.idle":"2023-04-28T23:55:06.924204Z","shell.execute_reply.started":"2023-04-28T23:55:06.073335Z","shell.execute_reply":"2023-04-28T23:55:06.922872Z"},"trusted":true},"execution_count":103,"outputs":[{"name":"stdout","text":"gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='gnn_15/StatefulPartitionedCall:0', description=\"created by layer 'gnn_15'\")\nmean: KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='tf.math.segment_mean_9/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_9'\")\npred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_22/Sigmoid:0', description=\"created by layer 'dense_22'\")\n","output_type":"stream"}]},{"cell_type":"code","source":"#printing summary of the model\nmodel_2.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-28T23:55:06.926732Z","iopub.execute_input":"2023-04-28T23:55:06.927696Z","iopub.status.idle":"2023-04-28T23:55:06.975396Z","shell.execute_reply.started":"2023-04-28T23:55:06.927647Z","shell.execute_reply":"2023-04-28T23:55:06.974033Z"},"trusted":true},"execution_count":104,"outputs":[{"name":"stdout","text":"Model: \"model_9\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_48 (InputLayer)          [(None,)]            0           []                               \n                                                                                                  \n input_46 (InputLayer)          [(None,)]            0           []                               \n                                                                                                  \n tf.math.reduce_max_15 (TFOpLam  ()                  0           ['input_48[0][0]']               \n bda)                                                                                             \n                                                                                                  \n embedding_15 (Embedding)       (None, 75)           37500       ['input_46[0][0]']               \n                                                                                                  \n input_47 (InputLayer)          [(None, 2)]          0           []                               \n                                                                                                  \n tf.__operators__.add_15 (TFOpL  ()                  0           ['tf.math.reduce_max_15[0][0]']  \n ambda)                                                                                           \n                                                                                                  \n gnn_15 (GNN)                   (None, 32)           49568       ['embedding_15[0][0]',           \n                                                                  'input_47[0][0]',               \n                                                                  'input_48[0][0]',               \n                                                                  'tf.__operators__.add_15[0][0]']\n                                                                                                  \n tf.math.segment_mean_9 (TFOpLa  (None, 32)          0           ['gnn_15[0][0]',                 \n mbda)                                                            'input_48[0][0]']               \n                                                                                                  \n dense_21 (Dense)               (None, 8)            264         ['tf.math.segment_mean_9[0][0]'] \n                                                                                                  \n dense_22 (Dense)               (None, 1)            9           ['dense_21[0][0]']               \n                                                                                                  \n==================================================================================================\nTotal params: 87,341\nTrainable params: 87,341\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"#I will create Adam Optimizer for training optimizer with this hyperparameters\nad = tf.keras.optimizers.Adam(\n    learning_rate=0.001,\n    beta_1=0.9,\n    beta_2=0.999,\n    epsilon=1e-07,\n    amsgrad=False,\n    name=\"Adam\"\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T23:55:07.896514Z","iopub.execute_input":"2023-04-28T23:55:07.897430Z","iopub.status.idle":"2023-04-28T23:55:07.907574Z","shell.execute_reply.started":"2023-04-28T23:55:07.897384Z","shell.execute_reply":"2023-04-28T23:55:07.906380Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"code","source":"#compile the model by using my adam optimizer and BinaryCrossentropy loss\nmodel_2.compile(\n    optimizer = ad, \n    loss='BinaryCrossentropy',\n    metrics=['AUC']\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T23:55:09.670337Z","iopub.execute_input":"2023-04-28T23:55:09.670750Z","iopub.status.idle":"2023-04-28T23:55:09.686274Z","shell.execute_reply.started":"2023-04-28T23:55:09.670716Z","shell.execute_reply":"2023-04-28T23:55:09.684867Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\n\n#math.ceil: returns the smallest integral value greater than the number\n#no. of batches for training data\nnum_batchs = math.ceil(len(training_set) / batch_size)\n\n#no. of batches for validation data\nnum_batchs_validation = math.ceil(len(validation_set) / batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T23:55:10.819337Z","iopub.execute_input":"2023-04-28T23:55:10.819755Z","iopub.status.idle":"2023-04-28T23:55:10.826804Z","shell.execute_reply.started":"2023-04-28T23:55:10.819721Z","shell.execute_reply":"2023-04-28T23:55:10.825102Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"code","source":"#fit the models with 30 epoch and using early stopping to avoid overfitting\nhist_2 = model_2.fit(\n    gen_batch(\n        training_set, batch_size=batch_size, repeat=True\n    ),\n    steps_per_epoch=num_batchs,\n    epochs=30,\n    validation_data=gen_batch(\n        validation_set, batch_size=32, repeat=True\n    ),\n    validation_steps=num_batchs_validation,\n   callbacks=tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 3),\n    verbose=1\n)\nprint(hist_2)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T23:55:11.909349Z","iopub.execute_input":"2023-04-28T23:55:11.910101Z","iopub.status.idle":"2023-04-29T00:04:25.138823Z","shell.execute_reply.started":"2023-04-28T23:55:11.910032Z","shell.execute_reply":"2023-04-29T00:04:25.137580Z"},"trusted":true},"execution_count":108,"outputs":[{"name":"stdout","text":"Epoch 1/30\n626/626 [==============================] - 32s 42ms/step - loss: 0.2103 - auc: 0.5963 - val_loss: 0.1756 - val_auc: 0.6498\nEpoch 2/30\n626/626 [==============================] - 26s 41ms/step - loss: 0.1874 - auc: 0.6543 - val_loss: 0.1687 - val_auc: 0.6683\nEpoch 3/30\n626/626 [==============================] - 26s 41ms/step - loss: 0.1820 - auc: 0.6780 - val_loss: 0.1651 - val_auc: 0.6991\nEpoch 4/30\n626/626 [==============================] - 26s 41ms/step - loss: 0.1774 - auc: 0.7159 - val_loss: 0.1608 - val_auc: 0.7214\nEpoch 5/30\n626/626 [==============================] - 26s 42ms/step - loss: 0.1750 - auc: 0.7272 - val_loss: 0.1674 - val_auc: 0.6943\nEpoch 6/30\n626/626 [==============================] - 26s 41ms/step - loss: 0.1743 - auc: 0.7255 - val_loss: 0.1577 - val_auc: 0.7218\nEpoch 7/30\n626/626 [==============================] - 26s 41ms/step - loss: 0.1703 - auc: 0.7548 - val_loss: 0.1569 - val_auc: 0.7167\nEpoch 8/30\n626/626 [==============================] - 26s 42ms/step - loss: 0.1705 - auc: 0.7602 - val_loss: 0.1704 - val_auc: 0.7298\nEpoch 9/30\n626/626 [==============================] - 27s 42ms/step - loss: 0.1696 - auc: 0.7667 - val_loss: 0.1547 - val_auc: 0.7456\nEpoch 10/30\n626/626 [==============================] - 27s 43ms/step - loss: 0.1668 - auc: 0.7830 - val_loss: 0.1597 - val_auc: 0.7455\nEpoch 11/30\n626/626 [==============================] - 26s 42ms/step - loss: 0.1652 - auc: 0.7858 - val_loss: 0.1564 - val_auc: 0.7503\nEpoch 12/30\n626/626 [==============================] - 27s 43ms/step - loss: 0.1612 - auc: 0.7956 - val_loss: 0.1545 - val_auc: 0.7589\nEpoch 13/30\n626/626 [==============================] - 26s 41ms/step - loss: 0.1589 - auc: 0.8081 - val_loss: 0.1484 - val_auc: 0.7693\nEpoch 14/30\n626/626 [==============================] - 25s 40ms/step - loss: 0.1572 - auc: 0.8154 - val_loss: 0.1541 - val_auc: 0.7812\nEpoch 15/30\n626/626 [==============================] - 25s 40ms/step - loss: 0.1567 - auc: 0.8161 - val_loss: 0.1551 - val_auc: 0.7741\nEpoch 16/30\n626/626 [==============================] - 25s 40ms/step - loss: 0.1572 - auc: 0.8142 - val_loss: 0.1479 - val_auc: 0.7825\nEpoch 17/30\n626/626 [==============================] - 25s 39ms/step - loss: 0.1539 - auc: 0.8260 - val_loss: 0.1553 - val_auc: 0.7870\nEpoch 18/30\n626/626 [==============================] - 27s 43ms/step - loss: 0.1519 - auc: 0.8344 - val_loss: 0.1464 - val_auc: 0.7877\nEpoch 19/30\n626/626 [==============================] - 28s 44ms/step - loss: 0.1485 - auc: 0.8437 - val_loss: 0.1477 - val_auc: 0.8148\nEpoch 20/30\n626/626 [==============================] - 27s 43ms/step - loss: 0.1479 - auc: 0.8464 - val_loss: 0.1580 - val_auc: 0.7807\nEpoch 21/30\n626/626 [==============================] - 27s 43ms/step - loss: 0.1476 - auc: 0.8484 - val_loss: 0.1482 - val_auc: 0.8154\n<keras.callbacks.History object at 0x7281e2d53390>\n","output_type":"stream"}]},{"cell_type":"code","source":"#make a prediction by using the model\ny_pred_2 = model_2.predict(\n    gen_batch(testing_set, batch_size=32, shuffle=False)\n)\ny_pred_2 = np.reshape(y_pred_2, -1)","metadata":{"execution":{"iopub.status.busy":"2023-04-29T00:06:50.489102Z","iopub.execute_input":"2023-04-29T00:06:50.489618Z","iopub.status.idle":"2023-04-29T00:07:01.117802Z","shell.execute_reply.started":"2023-04-29T00:06:50.489583Z","shell.execute_reply":"2023-04-29T00:07:01.116197Z"},"trusted":true},"execution_count":109,"outputs":[{"name":"stdout","text":"386/386 [==============================] - 7s 16ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"#make a submission file to upload it on kaggle\nsubmission = pd.DataFrame({'label':y_pred_2})\nsubmission.index.name = 'id'\nsubmission.to_csv('trial_GGNN_.csv')\n\n# 0.818","metadata":{"execution":{"iopub.status.busy":"2023-04-29T00:07:04.219269Z","iopub.execute_input":"2023-04-29T00:07:04.220456Z","iopub.status.idle":"2023-04-29T00:07:04.256364Z","shell.execute_reply.started":"2023-04-29T00:07:04.220412Z","shell.execute_reply":"2023-04-29T00:07:04.254693Z"},"trusted":true},"execution_count":111,"outputs":[]},{"cell_type":"markdown","source":"**Expectation:**\n\n* The first three lines define the three input layers for the model.\n* The Embedding layer maps each token in the input data to a vector representation.\n* The GNNInput layer is a custom Keras layer that allows the GNN layer to take in the graph structure information as input.\n* The GNN layer is a graph neural network layer that applies a message-passing algorithm to the graph structure information and produces a graph-level output.\n* The segment_mean layer takes in the graph-level output from the GNN layer and computes the mean of the output for each graph in the batch.\n* The final Dense layer applies a non-linear transformation to the output of the segment_mean layer and produces a prediction with sigmoid activation.\n* Finally, the input and output layers are combined into a Model instance.\n\n**Observation:**\n\nMy model got a score of 0.818 on kaggle\n\n**Plan**\n\nI will change my hyperparameters to :\n\nparams[\"hidden_dim\"] = 64\n\nparams[\"message_calculation_class\"] = 'RGCN'\n\nparams[\"num_edge_MLP_hidden_layers\"] = 16\n\n\n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Trail_3 RGCN","metadata":{}},{"cell_type":"code","source":"#importing tensorflow and other libraries\n#GGNN,RGCN,RGAT,RGIN,GNN-Edge-MLP,GNN-FiLM\n#import tf2_gnn.layers.message_passing.gnn_edge_mlp\nfrom  tf2_gnn.layers.message_passing import rgat,rgin,rgcn,gnn_film,ggnn,gnn_edge_mlp\nimport tensorflow as tf\nfrom tensorflow.math import segment_mean #to calculate segmented mean\nfrom tensorflow import keras\nfrom tensorflow.keras import Input, Model #layers and model\nfrom tensorflow.keras.layers import Embedding, Dense #layers\nfrom tensorflow.keras.optimizers import Adam #optimizer\n\n\n#Input layer for nodes (tokenized text data)          \ndata = keras.Input(batch_shape=(None,)) \n# the first dim is different to the previous one. it is the total number of edges in this batch\n#Input layer for edge data        \nedge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)   \n#Input layer for node2graph ids    \nnode2graph = keras.Input(batch_shape=(None,), dtype=tf.int32) \n#embedding layer over data with each token embedded as  size vector\nembeded = Embedding(tokenizer.num_words, 50)(data)  \n\n# number of graphs (number of samples)\n#calculating number of samples (or min(batch_size,no._of_samples))  \nnum_graph = tf.reduce_max(node2graph)+1  \n#gnn_input layer with inputs as defined above\ngnn_input = GNNInput(\n    node_features=embeded,\n    adjacency_lists=(edge,),\n    node_to_graph_map=node2graph, \n    num_graphs=num_graph,\n)\n\n# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n#defining hyperparameters for GNN layer\nparams = GNN.get_default_hyperparameters()\n#defining hidden dimension of the gnn layer\nparams[\"hidden_dim\"] = 64\n#Relational Graph Convolutional Networks  \nparams[\"message_calculation_class\"] = 'RGCN'\nparams[\"num_edge_MLP_hidden_layers\"] = 16\n#gnn layer with defined hyperparameters\ngnn_layer = GNN(params)  \n\n#gnn output layer \n#outpur shape: [data_dimension,hidden layers]  \ngnn_out = gnn_layer(gnn_input) \n\nprint('gnn_out', gnn_out)           \n\n# https://www.tensorflow.org/api_docs/python/tf/math/segment_mean\n\n#calculating segmented mean based on segment_ids\navg = segment_mean(\n    data=gnn_out,\n    segment_ids=node2graph\n    )#shape: [batch_size,64] \n\nprint('mean:', avg)\n\n#final dense layer with sigmoid\n#Output [None,8]\nfc1 = Dense(8,activation='relu')(avg) \n#output shape: [batch_size,1] \npred = Dense(1, activation='sigmoid')(fc1)   \nprint('pred:', pred)\n\n#building model \n#inputs are data,edges and node2graph\n#input: dictionary\n#output: prediction value from dense layer\nmodel_3 = Model(\n    inputs={\n        'data': data, \n        'edges': edge,\n        'node2grah': node2graph,\n    },\n    outputs=pred\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-27T22:43:22.764485Z","iopub.execute_input":"2023-04-27T22:43:22.765032Z","iopub.status.idle":"2023-04-27T22:43:24.341007Z","shell.execute_reply.started":"2023-04-27T22:43:22.764984Z","shell.execute_reply":"2023-04-27T22:43:24.339553Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='gnn_2/StatefulPartitionedCall:0', description=\"created by layer 'gnn_2'\")\nmean: KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='tf.math.segment_mean_1/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_1'\")\npred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_3/Sigmoid:0', description=\"created by layer 'dense_3'\")\n","output_type":"stream"}]},{"cell_type":"code","source":"model_3.compile( loss='BinaryCrossentropy', metrics=['AUC'])","metadata":{"execution":{"iopub.status.busy":"2023-04-27T22:21:25.456062Z","iopub.execute_input":"2023-04-27T22:21:25.456550Z","iopub.status.idle":"2023-04-27T22:21:25.486021Z","shell.execute_reply.started":"2023-04-27T22:21:25.456499Z","shell.execute_reply":"2023-04-27T22:21:25.484837Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"#printing summary of the model\nmodel_3.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-27T22:21:25.487928Z","iopub.execute_input":"2023-04-27T22:21:25.488273Z","iopub.status.idle":"2023-04-27T22:21:25.539417Z","shell.execute_reply.started":"2023-04-27T22:21:25.488239Z","shell.execute_reply":"2023-04-27T22:21:25.537817Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_3 (InputLayer)           [(None,)]            0           []                               \n                                                                                                  \n input_1 (InputLayer)           [(None,)]            0           []                               \n                                                                                                  \n tf.math.reduce_max (TFOpLambda  ()                  0           ['input_3[0][0]']                \n )                                                                                                \n                                                                                                  \n embedding (Embedding)          (None, 50)           25000       ['input_1[0][0]']                \n                                                                                                  \n input_2 (InputLayer)           [(None, 2)]          0           []                               \n                                                                                                  \n tf.__operators__.add (TFOpLamb  ()                  0           ['tf.math.reduce_max[0][0]']     \n da)                                                                                              \n                                                                                                  \n gnn (GNN)                      (None, 64)           335616      ['embedding[0][0]',              \n                                                                  'input_2[0][0]',                \n                                                                  'input_3[0][0]',                \n                                                                  'tf.__operators__.add[0][0]']   \n                                                                                                  \n tf.math.segment_mean (TFOpLamb  (None, 64)          0           ['gnn[0][0]',                    \n da)                                                              'input_3[0][0]']                \n                                                                                                  \n dense (Dense)                  (None, 8)            520         ['tf.math.segment_mean[0][0]']   \n                                                                                                  \n dense_1 (Dense)                (None, 1)            9           ['dense[0][0]']                  \n                                                                                                  \n==================================================================================================\nTotal params: 361,145\nTrainable params: 361,145\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"import math\n\nbatch_size = 32\n\n#math.ceil: returns the smallest integral value greater than the number\n#no. of batches for training data\nnum_batchs = math.ceil(len(training_set) / batch_size) \n#no. of batches for validation data\nnum_batchs_validation = math.ceil(len(validation_set) / batch_size) \n\nmodel_3.fit(\n    gen_batch(\n        training_set, batch_size=batch_size, repeat=True\n    ),\n    steps_per_epoch=num_batchs,\n    epochs=20,\n    validation_data=gen_batch(\n        validation_set, batch_size=16, repeat=True\n    ),\n    validation_steps=num_batchs_validation,\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-27T22:21:25.540829Z","iopub.execute_input":"2023-04-27T22:21:25.541170Z","iopub.status.idle":"2023-04-27T22:40:19.588736Z","shell.execute_reply.started":"2023-04-27T22:21:25.541139Z","shell.execute_reply":"2023-04-27T22:40:19.587111Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Epoch 1/20\n626/626 [==============================] - 66s 92ms/step - loss: 0.3418 - auc: 0.4630 - val_loss: 0.2332 - val_auc: 0.3633\nEpoch 2/20\n626/626 [==============================] - 56s 89ms/step - loss: 0.2152 - auc: 0.4404 - val_loss: 0.1842 - val_auc: 0.6571\nEpoch 3/20\n626/626 [==============================] - 56s 90ms/step - loss: 0.1942 - auc: 0.5995 - val_loss: 0.1974 - val_auc: 0.6351\nEpoch 4/20\n626/626 [==============================] - 57s 90ms/step - loss: 0.1933 - auc: 0.5900 - val_loss: 0.1995 - val_auc: 0.5964\nEpoch 5/20\n626/626 [==============================] - 56s 90ms/step - loss: 0.1921 - auc: 0.6178 - val_loss: 0.1891 - val_auc: 0.5701\nEpoch 6/20\n626/626 [==============================] - 56s 90ms/step - loss: 0.1906 - auc: 0.6239 - val_loss: 0.2046 - val_auc: 0.6262\nEpoch 7/20\n626/626 [==============================] - 56s 89ms/step - loss: 0.1913 - auc: 0.6121 - val_loss: 0.1890 - val_auc: 0.6200\nEpoch 8/20\n626/626 [==============================] - 56s 89ms/step - loss: 0.1903 - auc: 0.6288 - val_loss: 0.2056 - val_auc: 0.6194\nEpoch 9/20\n626/626 [==============================] - 56s 89ms/step - loss: 0.1891 - auc: 0.6398 - val_loss: 0.2007 - val_auc: 0.6544\nEpoch 10/20\n626/626 [==============================] - 56s 90ms/step - loss: 0.1893 - auc: 0.6406 - val_loss: 0.1835 - val_auc: 0.6019\nEpoch 11/20\n626/626 [==============================] - 57s 91ms/step - loss: 0.1885 - auc: 0.6387 - val_loss: 0.1902 - val_auc: 0.6129\nEpoch 12/20\n626/626 [==============================] - 56s 90ms/step - loss: 0.1892 - auc: 0.6285 - val_loss: 0.1869 - val_auc: 0.6686\nEpoch 13/20\n626/626 [==============================] - 56s 90ms/step - loss: 0.1889 - auc: 0.6359 - val_loss: 0.1825 - val_auc: 0.6667\nEpoch 14/20\n626/626 [==============================] - 56s 89ms/step - loss: 0.1888 - auc: 0.6358 - val_loss: 0.1981 - val_auc: 0.5742\nEpoch 15/20\n626/626 [==============================] - 56s 89ms/step - loss: 0.1895 - auc: 0.6327 - val_loss: 0.2011 - val_auc: 0.5978\nEpoch 16/20\n626/626 [==============================] - 56s 90ms/step - loss: 0.1886 - auc: 0.6362 - val_loss: 0.1905 - val_auc: 0.6090\nEpoch 17/20\n626/626 [==============================] - 56s 90ms/step - loss: 0.1880 - auc: 0.6330 - val_loss: 0.1934 - val_auc: 0.6756\nEpoch 18/20\n626/626 [==============================] - 56s 90ms/step - loss: 0.1870 - auc: 0.6439 - val_loss: 0.1936 - val_auc: 0.5814\nEpoch 19/20\n626/626 [==============================] - 56s 90ms/step - loss: 0.1862 - auc: 0.6460 - val_loss: 0.1915 - val_auc: 0.6234\nEpoch 20/20\n626/626 [==============================] - 56s 90ms/step - loss: 0.1860 - auc: 0.6456 - val_loss: 0.1989 - val_auc: 0.6692\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x78862f542550>"},"metadata":{}}]},{"cell_type":"code","source":"\n#make prediction on test data by using the trained model \ny_pred_3 = model_3.predict(\n    gen_batch(testing_set, batch_size=16, shuffle=False)\n)\ny_pred_3 = np.reshape(y_pred_3, -1)","metadata":{"execution":{"iopub.status.busy":"2023-04-27T22:40:19.592364Z","iopub.execute_input":"2023-04-27T22:40:19.593359Z","iopub.status.idle":"2023-04-27T22:40:34.053462Z","shell.execute_reply.started":"2023-04-27T22:40:19.593303Z","shell.execute_reply":"2023-04-27T22:40:34.051777Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"771/771 [==============================] - 14s 17ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd \nsubmission = pd.DataFrame({'label':y_pred_3})\nsubmission.index.name = 'id'\nsubmission.to_csv('submission_RGCN.csv')\n#0.6756","metadata":{"execution":{"iopub.status.busy":"2023-04-27T22:40:43.220277Z","iopub.execute_input":"2023-04-27T22:40:43.220703Z","iopub.status.idle":"2023-04-27T22:40:43.264189Z","shell.execute_reply.started":"2023-04-27T22:40:43.220665Z","shell.execute_reply":"2023-04-27T22:40:43.262970Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"**Expectation:**\n\n* The first three lines define the three input layers for the model.\n* The Embedding layer maps each token in the input data to a vector representation.\n* The GNNInput layer is a custom Keras layer that allows the GNN layer to take in the graph structure information as input.\n* The GNN layer is a graph neural network layer that applies a message-passing algorithm to the graph structure information and produces a graph-level output.\n* The segment_mean layer takes in the graph-level output from the GNN layer and computes the mean of the output for each graph in the batch.\n* The final Dense layer applies a non-linear transformation to the output of the segment_mean layer and produces a prediction with sigmoid activation.\n* Finally, the input and output layers are combined into a Model instance.\n\n**Observation:**\n\nMy model got a score of 0.6756 on kaggle\n\n**Plan**\n\nI will change my hyperparameters to :\n\nparams[\"hidden_dim\"] = 32\n\nparams[\"message_calculation_class\"] = 'RGAT'\n\nparams[\"num_edge_MLP_hidden_layers\"] = 16\n\nparams[\"num_heads\"] = 16","metadata":{}},{"cell_type":"markdown","source":"# Trial_4(RGAT)","metadata":{}},{"cell_type":"code","source":"#Input layer for nodes (tokenized text data)\ndata = keras.Input(batch_shape=(None,))\n\n# the first dim is different to the previous one. it is the total number of edges in this batch\n#Input layer for edge data\nedge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n#Input layer for node2graph ids\nnode2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n\n#embedding layer over data with each token embedded as a vector   size vector eg. [440,75]\nembeded = Embedding(tokenizer.num_words, 70)(data)\n\n# number of graphs (number of samples)\n#calculating number of samples (or min(batch_size,no._of_samples))\nnum_graph = tf.reduce_max(node2graph)+1  \n\n#gnn_input layer with inputs as defined above\ngnn_input = GNNInput(\n    node_features=embeded,\n    adjacency_lists=(edge,),\n    node_to_graph_map=node2graph, \n    num_graphs=num_graph,\n)\n\n#defining hyperparameters for GNN layer\nparams = GNN.get_default_hyperparameters()\n#defining hidden dimension of the gnn layer\nparams[\"hidden_dim\"] = 32\nparams[\"message_calculation_class\"] = 'RGAT'\nparams[\"num_edge_MLP_hidden_layers\"] = 16\nparams[\"num_heads\"] = 16\n# params[\"num_layers\"] = 4\n# params[\"dense_every_num_layers\"] = 4\n\n\n\n#gnn layer with defined hyperparameters\ngnn_layer = GNN(params) \n\n#gnn output layer\n#outpur shape: [data_dimension,hidden layers]\ngnn_out = gnn_layer(gnn_input)\n\nprint('gnn_out', gnn_out)           \n\n#calculating segmented mean based on segment_ids\navg = segment_mean(\n    data=gnn_out,\n    segment_ids=node2graph\n    )\n\nprint('mean:', avg)\n\n#final dense layer with sigmoid\n#Output [None,8]\nfc1 = Dense(64,activation='relu')(avg)\nfc2 = Dense(32,activation='relu')(fc1)\n# d1 = Dropout(0.2)(fc2)\n\n#output shape: [batch_size,1] \npred = Dense(1, activation='sigmoid')(fc2)\nprint('pred:', pred)\n\n#Building The Model \n#inputs is dictionary of data, edges, node2graph\n#output: prediction value from dense layer\nmodel_4 = Model(\n    inputs={\n        'data': data, \n        'edges': edge,\n        'node2grah': node2graph,\n    },\n    outputs=pred\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T20:57:35.844313Z","iopub.execute_input":"2023-04-28T20:57:35.844814Z","iopub.status.idle":"2023-04-28T20:57:38.157682Z","shell.execute_reply.started":"2023-04-28T20:57:35.844776Z","shell.execute_reply":"2023-04-28T20:57:38.156078Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='gnn_1/StatefulPartitionedCall:0', description=\"created by layer 'gnn_1'\")\nmean: KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='tf.math.segment_mean_1/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_1'\")\npred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_4/Sigmoid:0', description=\"created by layer 'dense_4'\")\n","output_type":"stream"}]},{"cell_type":"code","source":"#printing summary of the model\nmodel_4.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-28T20:57:38.160036Z","iopub.execute_input":"2023-04-28T20:57:38.160415Z","iopub.status.idle":"2023-04-28T20:57:38.218379Z","shell.execute_reply.started":"2023-04-28T20:57:38.160381Z","shell.execute_reply":"2023-04-28T20:57:38.216552Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Model: \"model_1\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_6 (InputLayer)           [(None,)]            0           []                               \n                                                                                                  \n input_4 (InputLayer)           [(None,)]            0           []                               \n                                                                                                  \n tf.math.reduce_max_1 (TFOpLamb  ()                  0           ['input_6[0][0]']                \n da)                                                                                              \n                                                                                                  \n embedding_1 (Embedding)        (None, 70)           35000       ['input_4[0][0]']                \n                                                                                                  \n input_5 (InputLayer)           [(None, 2)]          0           []                               \n                                                                                                  \n tf.__operators__.add_1 (TFOpLa  ()                  0           ['tf.math.reduce_max_1[0][0]']   \n mbda)                                                                                            \n                                                                                                  \n gnn_1 (GNN)                    (None, 32)           24320       ['embedding_1[0][0]',            \n                                                                  'input_5[0][0]',                \n                                                                  'input_6[0][0]',                \n                                                                  'tf.__operators__.add_1[0][0]'] \n                                                                                                  \n tf.math.segment_mean_1 (TFOpLa  (None, 32)          0           ['gnn_1[0][0]',                  \n mbda)                                                            'input_6[0][0]']                \n                                                                                                  \n dense_2 (Dense)                (None, 64)           2112        ['tf.math.segment_mean_1[0][0]'] \n                                                                                                  \n dense_3 (Dense)                (None, 32)           2080        ['dense_2[0][0]']                \n                                                                                                  \n dense_4 (Dense)                (None, 1)            33          ['dense_3[0][0]']                \n                                                                                                  \n==================================================================================================\nTotal params: 63,545\nTrainable params: 63,545\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"#compile the model by using adam optimizer and BinaryCrossentropy loss\nmodel_4.compile(\n    optimizer = 'adam', \n    loss='BinaryCrossentropy',\n    metrics=['AUC']\n)\n  ","metadata":{"execution":{"iopub.status.busy":"2023-04-28T20:57:38.220320Z","iopub.execute_input":"2023-04-28T20:57:38.220822Z","iopub.status.idle":"2023-04-28T20:57:38.243880Z","shell.execute_reply.started":"2023-04-28T20:57:38.220770Z","shell.execute_reply":"2023-04-28T20:57:38.242515Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\n\n#math.ceil: returns the smallest integral value greater than the number\n#no. of batches for training data\nnum_batchs = math.ceil(len(training_set) / batch_size)\n\n#no. of batches for validation data\nnum_batchs_validation = math.ceil(len(validation_set) / batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T20:57:39.256110Z","iopub.execute_input":"2023-04-28T20:57:39.256609Z","iopub.status.idle":"2023-04-28T20:57:39.263875Z","shell.execute_reply.started":"2023-04-28T20:57:39.256572Z","shell.execute_reply":"2023-04-28T20:57:39.262139Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"#fit the models with 30 epoch and using early stopping to avoid overfitting\nhist_4 = model_4.fit(\n    gen_batch(\n        training_set, batch_size=batch_size, repeat=True\n    ),\n    steps_per_epoch=num_batchs,\n    epochs=30,\n    validation_data=gen_batch(\n        validation_set, batch_size=64, repeat=True\n    ),\n    validation_steps=num_batchs_validation,\n  #  callbacks=tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 3),\n    # verbose=1\n)\nprint(hist_4)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T20:57:42.832471Z","iopub.execute_input":"2023-04-28T20:57:42.833013Z","iopub.status.idle":"2023-04-28T21:18:08.920517Z","shell.execute_reply.started":"2023-04-28T20:57:42.832957Z","shell.execute_reply":"2023-04-28T21:18:08.919567Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Epoch 1/30\n626/626 [==============================] - 68s 79ms/step - loss: 0.2216 - auc: 0.5600 - val_loss: 0.1969 - val_auc: 0.6599\nEpoch 2/30\n626/626 [==============================] - 43s 68ms/step - loss: 0.1845 - auc: 0.6583 - val_loss: 0.1778 - val_auc: 0.6979\nEpoch 3/30\n626/626 [==============================] - 42s 68ms/step - loss: 0.1803 - auc: 0.6912 - val_loss: 0.1780 - val_auc: 0.7110\nEpoch 4/30\n626/626 [==============================] - 41s 66ms/step - loss: 0.1775 - auc: 0.7157 - val_loss: 0.1761 - val_auc: 0.7209\nEpoch 5/30\n626/626 [==============================] - 46s 73ms/step - loss: 0.1757 - auc: 0.7186 - val_loss: 0.1742 - val_auc: 0.7216\nEpoch 6/30\n626/626 [==============================] - 41s 66ms/step - loss: 0.1735 - auc: 0.7336 - val_loss: 0.1767 - val_auc: 0.7411\nEpoch 7/30\n626/626 [==============================] - 40s 65ms/step - loss: 0.1744 - auc: 0.7322 - val_loss: 0.1713 - val_auc: 0.7428\nEpoch 8/30\n626/626 [==============================] - 40s 64ms/step - loss: 0.1724 - auc: 0.7404 - val_loss: 0.1705 - val_auc: 0.7550\nEpoch 9/30\n626/626 [==============================] - 40s 64ms/step - loss: 0.1726 - auc: 0.7410 - val_loss: 0.1736 - val_auc: 0.7511\nEpoch 10/30\n626/626 [==============================] - 40s 64ms/step - loss: 0.1701 - auc: 0.7575 - val_loss: 0.1692 - val_auc: 0.7651\nEpoch 11/30\n626/626 [==============================] - 46s 74ms/step - loss: 0.1687 - auc: 0.7589 - val_loss: 0.1704 - val_auc: 0.7620\nEpoch 12/30\n626/626 [==============================] - 41s 66ms/step - loss: 0.1670 - auc: 0.7653 - val_loss: 0.1692 - val_auc: 0.7561\nEpoch 13/30\n626/626 [==============================] - 41s 66ms/step - loss: 0.1655 - auc: 0.7731 - val_loss: 0.1666 - val_auc: 0.7707\nEpoch 14/30\n626/626 [==============================] - 41s 66ms/step - loss: 0.1636 - auc: 0.7856 - val_loss: 0.1638 - val_auc: 0.7778\nEpoch 15/30\n626/626 [==============================] - 41s 65ms/step - loss: 0.1632 - auc: 0.7841 - val_loss: 0.1648 - val_auc: 0.7793\nEpoch 16/30\n626/626 [==============================] - 41s 65ms/step - loss: 0.1622 - auc: 0.7892 - val_loss: 0.1693 - val_auc: 0.7779\nEpoch 17/30\n626/626 [==============================] - 40s 64ms/step - loss: 0.1604 - auc: 0.7966 - val_loss: 0.1637 - val_auc: 0.7889\nEpoch 18/30\n626/626 [==============================] - 40s 64ms/step - loss: 0.1601 - auc: 0.8007 - val_loss: 0.1617 - val_auc: 0.7900\nEpoch 19/30\n626/626 [==============================] - 38s 61ms/step - loss: 0.1586 - auc: 0.8017 - val_loss: 0.1622 - val_auc: 0.7880\nEpoch 20/30\n626/626 [==============================] - 38s 61ms/step - loss: 0.1580 - auc: 0.8067 - val_loss: 0.1572 - val_auc: 0.8010\nEpoch 21/30\n626/626 [==============================] - 38s 61ms/step - loss: 0.1564 - auc: 0.8115 - val_loss: 0.1605 - val_auc: 0.7987\nEpoch 22/30\n626/626 [==============================] - 39s 62ms/step - loss: 0.1555 - auc: 0.8123 - val_loss: 0.1608 - val_auc: 0.7989\nEpoch 23/30\n626/626 [==============================] - 38s 61ms/step - loss: 0.1539 - auc: 0.8193 - val_loss: 0.1566 - val_auc: 0.8012\nEpoch 24/30\n626/626 [==============================] - 38s 60ms/step - loss: 0.1536 - auc: 0.8217 - val_loss: 0.1569 - val_auc: 0.8035\nEpoch 25/30\n626/626 [==============================] - 38s 60ms/step - loss: 0.1503 - auc: 0.8322 - val_loss: 0.1569 - val_auc: 0.8061\nEpoch 26/30\n626/626 [==============================] - 37s 59ms/step - loss: 0.1506 - auc: 0.8282 - val_loss: 0.1570 - val_auc: 0.8044\nEpoch 27/30\n626/626 [==============================] - 38s 60ms/step - loss: 0.1500 - auc: 0.8342 - val_loss: 0.1573 - val_auc: 0.7996\nEpoch 28/30\n626/626 [==============================] - 37s 59ms/step - loss: 0.1494 - auc: 0.8327 - val_loss: 0.1561 - val_auc: 0.8166\nEpoch 29/30\n626/626 [==============================] - 37s 60ms/step - loss: 0.1484 - auc: 0.8361 - val_loss: 0.1562 - val_auc: 0.8141\nEpoch 30/30\n626/626 [==============================] - 38s 60ms/step - loss: 0.1466 - auc: 0.8418 - val_loss: 0.1529 - val_auc: 0.8167\n<keras.callbacks.History object at 0x728244882d10>\n","output_type":"stream"}]},{"cell_type":"code","source":"\n#make a prediction by using the model\ny_pred_4 = model_4.predict(\n    gen_batch(testing_set, batch_size=32, shuffle=False)\n)\ny_pred_4 = np.reshape(y_pred_4, -1)","metadata":{"execution":{"iopub.status.busy":"2023-04-26T14:30:19.699635Z","iopub.execute_input":"2023-04-26T14:30:19.700090Z","iopub.status.idle":"2023-04-26T14:30:27.448623Z","shell.execute_reply.started":"2023-04-26T14:30:19.700042Z","shell.execute_reply":"2023-04-26T14:30:27.447365Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"386/386 [==============================] - 8s 17ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"#make a submission file to upload it on kaggle\nsubmission = pd.DataFrame({'label':y_pred_4})\nsubmission.index.name = 'id'\nsubmission.to_csv('trial_RGAT.csv')","metadata":{"execution":{"iopub.status.busy":"2023-04-26T14:30:27.450441Z","iopub.execute_input":"2023-04-26T14:30:27.451296Z","iopub.status.idle":"2023-04-26T14:30:27.486365Z","shell.execute_reply.started":"2023-04-26T14:30:27.451245Z","shell.execute_reply":"2023-04-26T14:30:27.484870Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":"**Expectation:**\n\n It starts by getting the default hyperparameters using the get_default_hyperparameters() method of the GNN class. It then sets the number of features per node to 32, the message-passing algorithm to use to 'RGAT', the number of hidden layers in the edge MLP to 16, and the number of attention heads to 16. These hyperparameters determine how the GNN layer will process the input graph data and propagate information through the graph, and can be adjusted to improve the performance of the GNN layer for a given task or dataset.\n\n**Observation:**\n\nMy model got a score of 0.82838 on kaggle\n\n**Plan**\n\nI will change my hyperparameters to :\n\nparams[\"hidden_dim\"] = 64\n\nparams[\"message_calculation_class\"] = 'RGCN'","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  Trail_5 ","metadata":{}},{"cell_type":"code","source":"#importing tensorflow and other libraries\n#GGNN,RGCN,RGAT,RGIN,GNN-Edge-MLP,GNN-FiLM\n#import tf2_gnn.layers.message_passing.gnn_edge_mlp\nfrom  tf2_gnn.layers.message_passing import rgat,rgin,rgcn,gnn_film,ggnn,gnn_edge_mlp\nimport tensorflow as tf\nfrom tensorflow.math import segment_mean #to calculate segmented mean\nfrom tensorflow import keras\nfrom tensorflow.keras import Input, Model #layers and model\nfrom tensorflow.keras.layers import Embedding, Dense #layers\nfrom tensorflow.keras.optimizers import Adam #optimizer\n\n\n#Input layer for nodes (tokenized text data)          \ndata = keras.Input(batch_shape=(None,)) \n# the first dim is different to the previous one. it is the total number of edges in this batch\n#Input layer for edge data        \nedge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)   \n#Input layer for node2graph ids    \nnode2graph = keras.Input(batch_shape=(None,), dtype=tf.int32) \n#embedding layer over data with each token embedded as  size vector\nembeded = Embedding(tokenizer.num_words, 50)(data)  \n\n# number of graphs (number of samples)\n#calculating number of samples (or min(batch_size,no._of_samples))  \nnum_graph = tf.reduce_max(node2graph)+1  \n#gnn_input layer with inputs as defined above\ngnn_input = GNNInput(\n    node_features=embeded,\n    adjacency_lists=(edge,),\n    node_to_graph_map=node2graph, \n    num_graphs=num_graph,\n)\n\n# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n#defining hyperparameters for GNN layer\nparams = GNN.get_default_hyperparameters()\n#defining hidden dimension of the gnn layer\nparams[\"hidden_dim\"] = 64\n#Relational Graph Convolutional Networks  \nparams[\"message_calculation_class\"] = 'RGCN'\n# params[\"num_edge_MLP_hidden_layers\"] = 32\n#gnn layer with defined hyperparameters\ngnn_layer = GNN(params)  \n\n#gnn output layer \n#outpur shape: [data_dimension,hidden layers]  \ngnn_out = gnn_layer(gnn_input) \n\nprint('gnn_out', gnn_out)           \n\n# https://www.tensorflow.org/api_docs/python/tf/math/segment_mean\n\n#calculating segmented mean based on segment_ids\navg = segment_mean(\n    data=gnn_out,\n    segment_ids=node2graph\n    )#shape: [batch_size,64] \n\nprint('mean:', avg)\n\n#final dense layer with sigmoid\n#Output [None,8]\nfc1 = Dense(8,activation='LeakyReLU')(avg) \n#output shape: [batch_size,1] \npred = Dense(1, activation='sigmoid')(fc1)   \nprint('pred:', pred)\n\n#building model \n#inputs are data,edges and node2graph\n#input: dictionary\n#output: prediction value from dense layer\nmodel_5 = Model(\n    inputs={\n        'data': data, \n        'edges': edge,\n        'node2grah': node2graph,\n    },\n    outputs=pred\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-28T21:19:33.087660Z","iopub.execute_input":"2023-04-28T21:19:33.088158Z","iopub.status.idle":"2023-04-28T21:19:33.890799Z","shell.execute_reply.started":"2023-04-28T21:19:33.088119Z","shell.execute_reply":"2023-04-28T21:19:33.889345Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='gnn_2/StatefulPartitionedCall:0', description=\"created by layer 'gnn_2'\")\nmean: KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='tf.math.segment_mean_2/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_2'\")\npred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_6/Sigmoid:0', description=\"created by layer 'dense_6'\")\n","output_type":"stream"}]},{"cell_type":"code","source":"#printing summary of the model\nmodel_5.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-28T21:19:35.503586Z","iopub.execute_input":"2023-04-28T21:19:35.504896Z","iopub.status.idle":"2023-04-28T21:19:35.555965Z","shell.execute_reply.started":"2023-04-28T21:19:35.504847Z","shell.execute_reply":"2023-04-28T21:19:35.554374Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Model: \"model_2\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_9 (InputLayer)           [(None,)]            0           []                               \n                                                                                                  \n input_7 (InputLayer)           [(None,)]            0           []                               \n                                                                                                  \n tf.math.reduce_max_2 (TFOpLamb  ()                  0           ['input_9[0][0]']                \n da)                                                                                              \n                                                                                                  \n embedding_2 (Embedding)        (None, 50)           25000       ['input_7[0][0]']                \n                                                                                                  \n input_8 (InputLayer)           [(None, 2)]          0           []                               \n                                                                                                  \n tf.__operators__.add_2 (TFOpLa  ()                  0           ['tf.math.reduce_max_2[0][0]']   \n mbda)                                                                                            \n                                                                                                  \n gnn_2 (GNN)                    (None, 64)           73472       ['embedding_2[0][0]',            \n                                                                  'input_8[0][0]',                \n                                                                  'input_9[0][0]',                \n                                                                  'tf.__operators__.add_2[0][0]'] \n                                                                                                  \n tf.math.segment_mean_2 (TFOpLa  (None, 64)          0           ['gnn_2[0][0]',                  \n mbda)                                                            'input_9[0][0]']                \n                                                                                                  \n dense_5 (Dense)                (None, 8)            520         ['tf.math.segment_mean_2[0][0]'] \n                                                                                                  \n dense_6 (Dense)                (None, 1)            9           ['dense_5[0][0]']                \n                                                                                                  \n==================================================================================================\nTotal params: 99,001\nTrainable params: 99,001\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model_5.compile( loss='BinaryCrossentropy', metrics=['AUC'])","metadata":{"execution":{"iopub.status.busy":"2023-04-28T21:19:36.503337Z","iopub.execute_input":"2023-04-28T21:19:36.503748Z","iopub.status.idle":"2023-04-28T21:19:36.523255Z","shell.execute_reply.started":"2023-04-28T21:19:36.503714Z","shell.execute_reply":"2023-04-28T21:19:36.521792Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\n\n#math.ceil: returns the smallest integral value greater than the number\n#no. of batches for training data\nnum_batchs = math.ceil(len(training_set) / batch_size)\n\n#no. of batches for validation data\nnum_batchs_validation = math.ceil(len(validation_set) / batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T21:19:37.564859Z","iopub.execute_input":"2023-04-28T21:19:37.565398Z","iopub.status.idle":"2023-04-28T21:19:37.572680Z","shell.execute_reply.started":"2023-04-28T21:19:37.565355Z","shell.execute_reply":"2023-04-28T21:19:37.571208Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"model_5.fit(\n    gen_batch(\n        training_set, batch_size=batch_size, repeat=True\n    ),\n    steps_per_epoch=num_batchs,\n    epochs=30,\n    validation_data=gen_batch(\n        validation_set, batch_size=64, repeat=True\n    ),\n    validation_steps=num_batchs_validation,\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T21:19:40.795074Z","iopub.execute_input":"2023-04-28T21:19:40.796328Z","iopub.status.idle":"2023-04-28T21:33:45.013222Z","shell.execute_reply.started":"2023-04-28T21:19:40.796283Z","shell.execute_reply":"2023-04-28T21:33:45.011900Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Epoch 1/30\n626/626 [==============================] - 31s 44ms/step - loss: 0.2314 - auc: 0.5385 - val_loss: 0.1974 - val_auc: 0.6087\nEpoch 2/30\n626/626 [==============================] - 27s 43ms/step - loss: 0.1900 - auc: 0.6525 - val_loss: 0.1785 - val_auc: 0.6950\nEpoch 3/30\n626/626 [==============================] - 27s 43ms/step - loss: 0.1855 - auc: 0.6723 - val_loss: 0.1770 - val_auc: 0.7034\nEpoch 4/30\n626/626 [==============================] - 27s 43ms/step - loss: 0.1813 - auc: 0.6983 - val_loss: 0.1723 - val_auc: 0.7274\nEpoch 5/30\n626/626 [==============================] - 27s 44ms/step - loss: 0.1785 - auc: 0.7170 - val_loss: 0.1725 - val_auc: 0.7254\nEpoch 6/30\n626/626 [==============================] - 29s 46ms/step - loss: 0.1764 - auc: 0.7213 - val_loss: 0.1728 - val_auc: 0.7367\nEpoch 7/30\n626/626 [==============================] - 29s 46ms/step - loss: 0.1743 - auc: 0.7339 - val_loss: 0.1959 - val_auc: 0.6983\nEpoch 8/30\n626/626 [==============================] - 27s 43ms/step - loss: 0.1750 - auc: 0.7336 - val_loss: 0.1692 - val_auc: 0.7536\nEpoch 9/30\n626/626 [==============================] - 27s 44ms/step - loss: 0.1738 - auc: 0.7391 - val_loss: 0.1800 - val_auc: 0.7231\nEpoch 10/30\n626/626 [==============================] - 27s 43ms/step - loss: 0.1726 - auc: 0.7454 - val_loss: 0.1712 - val_auc: 0.7474\nEpoch 11/30\n626/626 [==============================] - 29s 46ms/step - loss: 0.1722 - auc: 0.7471 - val_loss: 0.1800 - val_auc: 0.7384\nEpoch 12/30\n626/626 [==============================] - 29s 46ms/step - loss: 0.1721 - auc: 0.7547 - val_loss: 0.1675 - val_auc: 0.7565\nEpoch 13/30\n626/626 [==============================] - 29s 46ms/step - loss: 0.1707 - auc: 0.7501 - val_loss: 0.1705 - val_auc: 0.7469\nEpoch 14/30\n626/626 [==============================] - 29s 47ms/step - loss: 0.1711 - auc: 0.7531 - val_loss: 0.1677 - val_auc: 0.7610\nEpoch 15/30\n626/626 [==============================] - 29s 46ms/step - loss: 0.1704 - auc: 0.7559 - val_loss: 0.1706 - val_auc: 0.7600\nEpoch 16/30\n626/626 [==============================] - 29s 46ms/step - loss: 0.1703 - auc: 0.7585 - val_loss: 0.1699 - val_auc: 0.7570\nEpoch 17/30\n626/626 [==============================] - 29s 47ms/step - loss: 0.1696 - auc: 0.7644 - val_loss: 0.1664 - val_auc: 0.7746\nEpoch 18/30\n626/626 [==============================] - 27s 44ms/step - loss: 0.1700 - auc: 0.7625 - val_loss: 0.1704 - val_auc: 0.7676\nEpoch 19/30\n626/626 [==============================] - 29s 47ms/step - loss: 0.1700 - auc: 0.7602 - val_loss: 0.1716 - val_auc: 0.7576\nEpoch 20/30\n626/626 [==============================] - 28s 44ms/step - loss: 0.1693 - auc: 0.7624 - val_loss: 0.1750 - val_auc: 0.7709\nEpoch 21/30\n626/626 [==============================] - 27s 43ms/step - loss: 0.1691 - auc: 0.7677 - val_loss: 0.1658 - val_auc: 0.7653\nEpoch 22/30\n626/626 [==============================] - 29s 47ms/step - loss: 0.1692 - auc: 0.7651 - val_loss: 0.1655 - val_auc: 0.7638\nEpoch 23/30\n626/626 [==============================] - 29s 46ms/step - loss: 0.1695 - auc: 0.7582 - val_loss: 0.1672 - val_auc: 0.7693\nEpoch 24/30\n626/626 [==============================] - 27s 43ms/step - loss: 0.1689 - auc: 0.7649 - val_loss: 0.1689 - val_auc: 0.7679\nEpoch 25/30\n626/626 [==============================] - 27s 43ms/step - loss: 0.1700 - auc: 0.7576 - val_loss: 0.1673 - val_auc: 0.7780\nEpoch 26/30\n626/626 [==============================] - 29s 46ms/step - loss: 0.1682 - auc: 0.7697 - val_loss: 0.1655 - val_auc: 0.7757\nEpoch 27/30\n626/626 [==============================] - 27s 43ms/step - loss: 0.1670 - auc: 0.7734 - val_loss: 0.1685 - val_auc: 0.7609\nEpoch 28/30\n626/626 [==============================] - 27s 43ms/step - loss: 0.1681 - auc: 0.7692 - val_loss: 0.1665 - val_auc: 0.7658\nEpoch 29/30\n626/626 [==============================] - 29s 46ms/step - loss: 0.1652 - auc: 0.7802 - val_loss: 0.1654 - val_auc: 0.7848\nEpoch 30/30\n626/626 [==============================] - 27s 43ms/step - loss: 0.1668 - auc: 0.7720 - val_loss: 0.1684 - val_auc: 0.7804\n","output_type":"stream"},{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x72824470fb90>"},"metadata":{}}]},{"cell_type":"code","source":"#make prediction on test data by using the trained model \ny_pred_5 = model_5.predict(\n    gen_batch(testing_set, batch_size=16, shuffle=False)\n)\ny_pred_5 = np.reshape(y_pred_5, -1)\n# 0.775","metadata":{"execution":{"iopub.status.busy":"2023-04-28T21:33:47.089384Z","iopub.execute_input":"2023-04-28T21:33:47.089894Z","iopub.status.idle":"2023-04-28T21:33:54.251928Z","shell.execute_reply.started":"2023-04-28T21:33:47.089851Z","shell.execute_reply":"2023-04-28T21:33:54.250408Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"771/771 [==============================] - 7s 8ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"submission = pd.DataFrame({'label':y_pred_5})\nsubmission.index.name = 'id'\nsubmission.to_csv('submission_model_5.csv')","metadata":{"execution":{"iopub.status.busy":"2023-04-28T21:33:54.254356Z","iopub.execute_input":"2023-04-28T21:33:54.254728Z","iopub.status.idle":"2023-04-28T21:33:54.293613Z","shell.execute_reply.started":"2023-04-28T21:33:54.254695Z","shell.execute_reply":"2023-04-28T21:33:54.292265Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"**Expectation:**\n\nThis code defines a neural network model that takes in tokenized text data, edge data, and node-to-graph mappings. It applies a graph neural network (GNN) layer to the data to build a graph structure, and produces a prediction using a final dense layer with sigmoid activation. The tf2_gnn library is used to import different types of message-passing algorithms for the GNN layer. The input and output layers are combined into a Model instance.\n\n**I expect it will give me accuracy around 75**\n\n**Observation:**\n\nMy model got a score of 0.775 on kaggle\n\n**Plan**\n\n**I plan to solve the problem of unbalanced data**","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Solve Unbalanced Data","metadata":{}},{"cell_type":"code","source":"#reading train.sdf file\ntraining_set_T2 = read_sdf('/kaggle/input/cisc873-dm-w23-a6/train.sdf')","metadata":{"execution":{"iopub.status.busy":"2023-04-28T21:33:57.243838Z","iopub.execute_input":"2023-04-28T21:33:57.244355Z","iopub.status.idle":"2023-04-28T21:34:00.979380Z","shell.execute_reply.started":"2023-04-28T21:33:57.244317Z","shell.execute_reply":"2023-04-28T21:34:00.977774Z"},"trusted":true},"execution_count":39,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/25024 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f70b49c7ebd4a5bbb13471f98f2ae10"}},"metadata":{}}]},{"cell_type":"code","source":"#checking for data balancing\nnp.unique(np.array(training_set_T2)[:,2],return_counts=True)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T21:34:00.981920Z","iopub.execute_input":"2023-04-28T21:34:00.982435Z","iopub.status.idle":"2023-04-28T21:34:01.036251Z","shell.execute_reply.started":"2023-04-28T21:34:00.982385Z","shell.execute_reply":"2023-04-28T21:34:01.035209Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n  \n","output_type":"stream"},{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"(array([0, 1], dtype=object), array([23806,  1218]))"},"metadata":{}}]},{"cell_type":"code","source":"#specify the length of the maximum freqent data to make the both labels have the same number of sample\nlen_0 = np.unique(np.array(training_set_T2)[:,2],return_counts=True)[1][0]\n","metadata":{"execution":{"iopub.status.busy":"2023-04-28T21:34:02.320696Z","iopub.execute_input":"2023-04-28T21:34:02.321173Z","iopub.status.idle":"2023-04-28T21:34:02.369878Z","shell.execute_reply.started":"2023-04-28T21:34:02.321133Z","shell.execute_reply":"2023-04-28T21:34:02.368370Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n  \n","output_type":"stream"}]},{"cell_type":"code","source":"len_0","metadata":{"execution":{"iopub.status.busy":"2023-04-28T21:34:03.639698Z","iopub.execute_input":"2023-04-28T21:34:03.640199Z","iopub.status.idle":"2023-04-28T21:34:03.648558Z","shell.execute_reply.started":"2023-04-28T21:34:03.640158Z","shell.execute_reply":"2023-04-28T21:34:03.647028Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"23806"},"metadata":{}}]},{"cell_type":"code","source":"#convert the data from List to DataFrame to make upsampling\ndata = pd.DataFrame(np.array(training_set_T2)[:,:], columns = ['0', '1', 'target'])","metadata":{"execution":{"iopub.status.busy":"2023-04-28T21:34:04.668133Z","iopub.execute_input":"2023-04-28T21:34:04.668567Z","iopub.status.idle":"2023-04-28T21:34:04.710591Z","shell.execute_reply.started":"2023-04-28T21:34:04.668530Z","shell.execute_reply":"2023-04-28T21:34:04.709303Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n  \n","output_type":"stream"}]},{"cell_type":"code","source":"\nfrom sklearn.utils import resample\n\nresampling = data.copy()  #take a copy of dataframe to make resampling\nclass_0 = resampling[resampling['target']==0]   #specify all rows which has target zero\nclass_1 = resampling[resampling['target']==1]   #specify all rows which has target one\nclass_1_after = resample(class_1, replace=True,n_samples = len_0)   #add data records to data frame with value one to make the number of rows which has target 0 == number of rows whic has target 1\ndf_upsampled = pd.concat([class_0, class_1_after])    #add the new rows to the new data frame","metadata":{"execution":{"iopub.status.busy":"2023-04-28T21:34:05.754589Z","iopub.execute_input":"2023-04-28T21:34:05.755060Z","iopub.status.idle":"2023-04-28T21:34:05.790635Z","shell.execute_reply.started":"2023-04-28T21:34:05.755021Z","shell.execute_reply":"2023-04-28T21:34:05.789427Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"# Display new class counts\ndf_upsampled['target'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-04-28T21:34:06.901046Z","iopub.execute_input":"2023-04-28T21:34:06.902327Z","iopub.status.idle":"2023-04-28T21:34:06.918821Z","shell.execute_reply.started":"2023-04-28T21:34:06.902262Z","shell.execute_reply":"2023-04-28T21:34:06.917183Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"0    23806\n1    23806\nName: target, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"#converting the upsampled DataFrame into list again to be easy to use the preprocessing methods on it\ntraining_set_T2 = df_upsampled.values.tolist()","metadata":{"execution":{"iopub.status.busy":"2023-04-28T21:34:07.980506Z","iopub.execute_input":"2023-04-28T21:34:07.980934Z","iopub.status.idle":"2023-04-28T21:34:08.003642Z","shell.execute_reply.started":"2023-04-28T21:34:07.980893Z","shell.execute_reply":"2023-04-28T21:34:08.002627Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"#splitting the train data into training and validation\ntraining_set, validation_set = train_test_split(training_set_T2, test_size=0.15)\nprint(type(training_set))","metadata":{"execution":{"iopub.status.busy":"2023-04-28T21:34:09.073365Z","iopub.execute_input":"2023-04-28T21:34:09.073829Z","iopub.status.idle":"2023-04-28T21:34:09.098135Z","shell.execute_reply.started":"2023-04-28T21:34:09.073793Z","shell.execute_reply":"2023-04-28T21:34:09.097166Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"<class 'list'>\n","output_type":"stream"}]},{"cell_type":"code","source":"\n#displaying one sample\nplt.clf()\nvisualize(training_set_T2[5])","metadata":{"execution":{"iopub.status.busy":"2023-04-28T21:34:10.905472Z","iopub.execute_input":"2023-04-28T21:34:10.905883Z","iopub.status.idle":"2023-04-28T21:34:11.116426Z","shell.execute_reply.started":"2023-04-28T21:34:10.905850Z","shell.execute_reply":"2023-04-28T21:34:11.114873Z"},"trusted":true},"execution_count":48,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"<networkx.classes.graph.Graph at 0x7281f61bc4d0>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"#vocabulary size\nmax_vocab = 500\n# maximum length of the tokenized vector\nmax_len = 100 \n\n# build vocabulary from training set only for nodes characters\nall_nodes = [s[0] for s in training_set_T2]\n\n#training tokenizer\ntokenizer = Tokenizer(num_words = max_vocab)\ntokenizer.fit_on_texts(all_nodes)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T21:34:16.160636Z","iopub.execute_input":"2023-04-28T21:34:16.161162Z","iopub.status.idle":"2023-04-28T21:34:16.886704Z","shell.execute_reply.started":"2023-04-28T21:34:16.161120Z","shell.execute_reply":"2023-04-28T21:34:16.885563Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"# showing one batch:\nfor train_batch in gen_batch(training_set_T2, batch_size=4):\n    for k,v in train_batch[0].items():\n        print(k)  \n        print(\"Shape is \"+str(np.shape(v)))\n        pass\n    print('label', train_batch[1])\n    break","metadata":{"execution":{"iopub.status.busy":"2023-04-28T21:34:17.994668Z","iopub.execute_input":"2023-04-28T21:34:17.995384Z","iopub.status.idle":"2023-04-28T21:34:18.056814Z","shell.execute_reply.started":"2023-04-28T21:34:17.995345Z","shell.execute_reply":"2023-04-28T21:34:18.055499Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"data\nShape is (252,)\nedges\nShape is (189, 2)\nnode2grah\nShape is (252,)\nlabel [1 1 1 1]\n","output_type":"stream"}]},{"cell_type":"code","source":"#Input layer for nodes (tokenized text data)\ndata = keras.Input(batch_shape=(None,))\n\n# the first dim is different to the previous one. it is the total number of edges in this batch\n#Input layer for edge data\nedge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n#Input layer for node2graph ids\nnode2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n\n#embedding layer over data with each token embedded as a vector   size vector eg. [440,75]\nembeded = Embedding(tokenizer.num_words, 70)(data)\n\n# number of graphs (number of samples)\n#calculating number of samples (or min(batch_size,no._of_samples))\nnum_graph = tf.reduce_max(node2graph)+1  \n\n#gnn_input layer with inputs as defined above\ngnn_input = GNNInput(\n    node_features=embeded,\n    adjacency_lists=(edge,),\n    node_to_graph_map=node2graph, \n    num_graphs=num_graph,\n)\n\n#defining hyperparameters for GNN layer\nparams = GNN.get_default_hyperparameters()\n#defining hidden dimension of the gnn layer\n\nparams[\"message_calculation_class\"] = 'RGCN'\nparams[\"hidden_dim\"] = 40\nparams[\"num_aggr_MLP_hidden_layers\"] = 2\nparams[\"num_edge_MLP_hidden_layers\"] = 2\nparams[\"num_heads\"] = 8\nparams[\"num_layers\"] = 4\nparams[\"dense_every_num_layers\"] = 1\nparams[\"film_parameter_MLP_hidden_layers\"] = 1\n\n#params[\"num_edge_MLP_hidden_layers\"] = 16\n\n#gnn layer with defined hyperparameters\ngnn_layer = GNN(params) \n\n#gnn output layer\n#outpur shape: [data_dimension,hidden layers]\ngnn_out = gnn_layer(gnn_input)\n\nprint('gnn_out', gnn_out)           \n\n#calculating segmented mean based on segment_ids\navg = segment_mean(\n    data=gnn_out,\n    segment_ids=node2graph\n    )\n\nprint('mean:', avg)\n\n#final dense layer with sigmoid\n#Output [None,8]\nfc1 = Dense(256,activation='relu')(avg)\nfc2 = Dense(128,activation='relu')(fc1)\nfc3 = Dense(64,activation='relu')(fc2)\n# d1 = Dropout(0.2)(fc2)\n\n#output shape: [batch_size,1] \npred = Dense(1, activation='sigmoid')(fc3)\nprint('pred:', pred)\n\n#Building The Model \n#inputs is dictionary of data, edges, node2graph\n#output: prediction value from dense layer\nmodel_6 = Model(\n    inputs={\n        'data': data, \n        'edges': edge,\n        'node2grah': node2graph,\n    },\n    outputs=pred\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T21:34:38.032708Z","iopub.execute_input":"2023-04-28T21:34:38.033175Z","iopub.status.idle":"2023-04-28T21:34:38.762800Z","shell.execute_reply.started":"2023-04-28T21:34:38.033134Z","shell.execute_reply":"2023-04-28T21:34:38.761557Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 40), dtype=tf.float32, name=None), name='gnn_4/StatefulPartitionedCall:0', description=\"created by layer 'gnn_4'\")\nmean: KerasTensor(type_spec=TensorSpec(shape=(None, 40), dtype=tf.float32, name=None), name='tf.math.segment_mean_4/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_4'\")\npred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_14/Sigmoid:0', description=\"created by layer 'dense_14'\")\n","output_type":"stream"}]},{"cell_type":"code","source":"#printing summary of the model\nmodel_6.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-28T21:34:38.876849Z","iopub.execute_input":"2023-04-28T21:34:38.878272Z","iopub.status.idle":"2023-04-28T21:34:38.937617Z","shell.execute_reply.started":"2023-04-28T21:34:38.878229Z","shell.execute_reply":"2023-04-28T21:34:38.936056Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"Model: \"model_4\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_15 (InputLayer)          [(None,)]            0           []                               \n                                                                                                  \n input_13 (InputLayer)          [(None,)]            0           []                               \n                                                                                                  \n tf.math.reduce_max_4 (TFOpLamb  ()                  0           ['input_15[0][0]']               \n da)                                                                                              \n                                                                                                  \n embedding_4 (Embedding)        (None, 70)           35000       ['input_13[0][0]']               \n                                                                                                  \n input_14 (InputLayer)          [(None, 2)]          0           []                               \n                                                                                                  \n tf.__operators__.add_4 (TFOpLa  ()                  0           ['tf.math.reduce_max_4[0][0]']   \n mbda)                                                                                            \n                                                                                                  \n gnn_4 (GNN)                    (None, 40)           50240       ['embedding_4[0][0]',            \n                                                                  'input_14[0][0]',               \n                                                                  'input_15[0][0]',               \n                                                                  'tf.__operators__.add_4[0][0]'] \n                                                                                                  \n tf.math.segment_mean_4 (TFOpLa  (None, 40)          0           ['gnn_4[0][0]',                  \n mbda)                                                            'input_15[0][0]']               \n                                                                                                  \n dense_11 (Dense)               (None, 256)          10496       ['tf.math.segment_mean_4[0][0]'] \n                                                                                                  \n dense_12 (Dense)               (None, 128)          32896       ['dense_11[0][0]']               \n                                                                                                  \n dense_13 (Dense)               (None, 64)           8256        ['dense_12[0][0]']               \n                                                                                                  \n dense_14 (Dense)               (None, 1)            65          ['dense_13[0][0]']               \n                                                                                                  \n==================================================================================================\nTotal params: 136,953\nTrainable params: 136,953\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"#I will create Adam Optimizer for training optimizer with this hyperparameters\nad = tf.keras.optimizers.Adam(\n    learning_rate=0.001,\n    beta_1=0.9,\n    beta_2=0.999,\n    epsilon=1e-07,\n    amsgrad=False,\n    name=\"Adam\"\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T21:34:40.585409Z","iopub.execute_input":"2023-04-28T21:34:40.585872Z","iopub.status.idle":"2023-04-28T21:34:40.595072Z","shell.execute_reply.started":"2023-04-28T21:34:40.585834Z","shell.execute_reply":"2023-04-28T21:34:40.593870Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"#compile the model by using my adam optimizer and BinaryCrossentropy loss\nmodel_6.compile(\n    optimizer = ad,\n    loss='BinaryCrossentropy',\n    metrics=['AUC']\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T21:34:42.328728Z","iopub.execute_input":"2023-04-28T21:34:42.330307Z","iopub.status.idle":"2023-04-28T21:34:42.343420Z","shell.execute_reply.started":"2023-04-28T21:34:42.330247Z","shell.execute_reply":"2023-04-28T21:34:42.342267Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"%%time\nbatch_size = 32\n#math.ceil: returns the smallest integral value greater than the number\n#no. of batches for training data\nnum_batchs = math.ceil(len(training_set) / batch_size)\n#no. of batches for validation data\nnum_batchs_validation = math.ceil(len(validation_set) / batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T21:34:43.181708Z","iopub.execute_input":"2023-04-28T21:34:43.182475Z","iopub.status.idle":"2023-04-28T21:34:43.190026Z","shell.execute_reply.started":"2023-04-28T21:34:43.182431Z","shell.execute_reply":"2023-04-28T21:34:43.189061Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"CPU times: user 16 s, sys: 0 ns, total: 16 s\nWall time: 21.9 s\n","output_type":"stream"}]},{"cell_type":"code","source":"#fit the models with 30 epoch and no early stopping\nhist = model_6.fit(\n    gen_batch(\n        training_set, batch_size=batch_size, repeat=True\n    ),\n    steps_per_epoch=num_batchs,\n    epochs=30,\n    validation_data=gen_batch(\n        validation_set, batch_size=32, repeat=True\n    ),\n    validation_steps=num_batchs_validation,\n    verbose=1\n)\nprint(hist)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T21:34:44.462926Z","iopub.execute_input":"2023-04-28T21:34:44.463745Z","iopub.status.idle":"2023-04-28T22:03:08.481789Z","shell.execute_reply.started":"2023-04-28T21:34:44.463702Z","shell.execute_reply":"2023-04-28T22:03:08.480544Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stdout","text":"Epoch 1/30\n1265/1265 [==============================] - 60s 43ms/step - loss: 0.6164 - auc: 0.7155 - val_loss: 0.5895 - val_auc: 0.7582\nEpoch 2/30\n1265/1265 [==============================] - 52s 41ms/step - loss: 0.5824 - auc: 0.7563 - val_loss: 0.5788 - val_auc: 0.7754\nEpoch 3/30\n1265/1265 [==============================] - 51s 41ms/step - loss: 0.5698 - auc: 0.7705 - val_loss: 0.5771 - val_auc: 0.7691\nEpoch 4/30\n1265/1265 [==============================] - 52s 41ms/step - loss: 0.5645 - auc: 0.7725 - val_loss: 0.5847 - val_auc: 0.7772\nEpoch 5/30\n1265/1265 [==============================] - 52s 41ms/step - loss: 0.5505 - auc: 0.7883 - val_loss: 0.5395 - val_auc: 0.8111\nEpoch 6/30\n1265/1265 [==============================] - 55s 43ms/step - loss: 0.5338 - auc: 0.8067 - val_loss: 0.5124 - val_auc: 0.8287\nEpoch 7/30\n1265/1265 [==============================] - 51s 41ms/step - loss: 0.5182 - auc: 0.8208 - val_loss: 0.5073 - val_auc: 0.8312\nEpoch 8/30\n1265/1265 [==============================] - 54s 43ms/step - loss: 0.4994 - auc: 0.8365 - val_loss: 0.4868 - val_auc: 0.8491\nEpoch 9/30\n1265/1265 [==============================] - 55s 44ms/step - loss: 0.4843 - auc: 0.8481 - val_loss: 0.4927 - val_auc: 0.8520\nEpoch 10/30\n1265/1265 [==============================] - 55s 44ms/step - loss: 0.4622 - auc: 0.8629 - val_loss: 0.4522 - val_auc: 0.8703\nEpoch 11/30\n1265/1265 [==============================] - 54s 43ms/step - loss: 0.4475 - auc: 0.8727 - val_loss: 0.4363 - val_auc: 0.8797\nEpoch 12/30\n1265/1265 [==============================] - 58s 45ms/step - loss: 0.4297 - auc: 0.8834 - val_loss: 0.4204 - val_auc: 0.8896\nEpoch 13/30\n1265/1265 [==============================] - 56s 44ms/step - loss: 0.4145 - auc: 0.8918 - val_loss: 0.4023 - val_auc: 0.8987\nEpoch 14/30\n1265/1265 [==============================] - 52s 41ms/step - loss: 0.4011 - auc: 0.8995 - val_loss: 0.3816 - val_auc: 0.9102\nEpoch 15/30\n1265/1265 [==============================] - 54s 42ms/step - loss: 0.3823 - auc: 0.9087 - val_loss: 0.3623 - val_auc: 0.9177\nEpoch 16/30\n1265/1265 [==============================] - 56s 44ms/step - loss: 0.3646 - auc: 0.9173 - val_loss: 0.3529 - val_auc: 0.9240\nEpoch 17/30\n1265/1265 [==============================] - 59s 47ms/step - loss: 0.3425 - auc: 0.9267 - val_loss: 0.3191 - val_auc: 0.9354\nEpoch 18/30\n1265/1265 [==============================] - 57s 45ms/step - loss: 0.3227 - auc: 0.9349 - val_loss: 0.3345 - val_auc: 0.9292\nEpoch 19/30\n1265/1265 [==============================] - 62s 49ms/step - loss: 0.3121 - auc: 0.9392 - val_loss: 0.2885 - val_auc: 0.9460\nEpoch 20/30\n1265/1265 [==============================] - 59s 47ms/step - loss: 0.3020 - auc: 0.9424 - val_loss: 0.2985 - val_auc: 0.9428\nEpoch 21/30\n1265/1265 [==============================] - 60s 47ms/step - loss: 0.3176 - auc: 0.9367 - val_loss: 0.3431 - val_auc: 0.9262\nEpoch 22/30\n1265/1265 [==============================] - 58s 46ms/step - loss: 0.3261 - auc: 0.9334 - val_loss: 0.3103 - val_auc: 0.9396\nEpoch 23/30\n1265/1265 [==============================] - 58s 46ms/step - loss: 0.3104 - auc: 0.9396 - val_loss: 0.3387 - val_auc: 0.9375\nEpoch 24/30\n1265/1265 [==============================] - 59s 47ms/step - loss: 0.2880 - auc: 0.9474 - val_loss: 0.2905 - val_auc: 0.9470\nEpoch 25/30\n1265/1265 [==============================] - 58s 46ms/step - loss: 0.2741 - auc: 0.9522 - val_loss: 0.2862 - val_auc: 0.9467\nEpoch 26/30\n1265/1265 [==============================] - 60s 47ms/step - loss: 0.2492 - auc: 0.9598 - val_loss: 0.2332 - val_auc: 0.9616\nEpoch 27/30\n1265/1265 [==============================] - 60s 48ms/step - loss: 0.2363 - auc: 0.9635 - val_loss: 0.2364 - val_auc: 0.9627\nEpoch 28/30\n1265/1265 [==============================] - 60s 48ms/step - loss: 0.2243 - auc: 0.9669 - val_loss: 0.2688 - val_auc: 0.9534\nEpoch 29/30\n1265/1265 [==============================] - 64s 51ms/step - loss: 0.2243 - auc: 0.9672 - val_loss: 0.2126 - val_auc: 0.9680\nEpoch 30/30\n1265/1265 [==============================] - 60s 48ms/step - loss: 0.2077 - auc: 0.9709 - val_loss: 0.2059 - val_auc: 0.9695\n<keras.callbacks.History object at 0x7281f5254b10>\n","output_type":"stream"}]},{"cell_type":"code","source":"#make a prediction by using the model\ny_pred_6 = model_6.predict(\n    gen_batch(testing_set, batch_size=32, shuffle=False)\n)\ny_pred_6 = np.reshape(y_pred_6, -1)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T22:03:12.788476Z","iopub.execute_input":"2023-04-28T22:03:12.788960Z","iopub.status.idle":"2023-04-28T22:03:19.080207Z","shell.execute_reply.started":"2023-04-28T22:03:12.788921Z","shell.execute_reply":"2023-04-28T22:03:19.078652Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stdout","text":"386/386 [==============================] - 6s 14ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"#make a submission file to upload it on kaggle\nsubmission = pd.DataFrame({'label':y_pred_6})\nsubmission.index.name = 'id'\nsubmission.to_csv('trail_6.csv')","metadata":{"execution":{"iopub.status.busy":"2023-04-28T22:03:19.082783Z","iopub.execute_input":"2023-04-28T22:03:19.083239Z","iopub.status.idle":"2023-04-28T22:03:19.123499Z","shell.execute_reply.started":"2023-04-28T22:03:19.083200Z","shell.execute_reply":"2023-04-28T22:03:19.121880Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"markdown","source":"**Expectation:**\n\nIt applies a graph neural network (GNN) layer to the data to build a graph structure, and produces a prediction using a final dense layer with sigmoid activation. The hyperparameters for the GNN layer are defined, and the input and output layers are combined into a Model instance.\n\n**I expect it will give me accuracy around 80**\n\n**Observation:**\n\nMy model got a score of 0.8069 on kaggle\n\n**Plan**\n\nI will change my hyperparameters to :\n\nparams[\"message_calculation_class\"] = 'RGCN'\n\nparams[\"hidden_dim\"] = 40\n\nparams[\"num_aggr_MLP_hidden_layers\"] = 2\n\nparams[\"num_edge_MLP_hidden_layers\"] = 2\n\nparams[\"num_heads\"] = 8\n\nparams[\"num_layers\"] = 4\n\nparams[\"dense_every_num_layers\"] = 1\n\nparams[\"film_parameter_MLP_hidden_layers\"] = 1\n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Trail_7 RGCN","metadata":{}},{"cell_type":"code","source":"#Input layer for nodes (tokenized text data)\ndata = keras.Input(batch_shape=(None,))\n\n# the first dim is different to the previous one. it is the total number of edges in this batch\n#Input layer for edge data\nedge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n#Input layer for node2graph ids\nnode2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n\n#embedding layer over data with each token embedded as a vector   size vector eg. [440,75]\nembeded = Embedding(tokenizer.num_words, 70)(data)\n\n# number of graphs (number of samples)\n#calculating number of samples (or min(batch_size,no._of_samples))\nnum_graph = tf.reduce_max(node2graph)+1  \n\n#gnn_input layer with inputs as defined above\ngnn_input = GNNInput(\n    node_features=embeded,\n    adjacency_lists=(edge,),\n    node_to_graph_map=node2graph, \n    num_graphs=num_graph,\n)\n\n#defining hyperparameters for GNN layer\nparams = GNN.get_default_hyperparameters()\n#defining hidden dimension of the gnn layer\n\nparams[\"message_calculation_class\"] = 'RGCN'\nparams[\"hidden_dim\"] = 40\nparams[\"num_aggr_MLP_hidden_layers\"] = 2\nparams[\"num_edge_MLP_hidden_layers\"] = 2\nparams[\"num_heads\"] = 8\nparams[\"num_layers\"] = 4\nparams[\"dense_every_num_layers\"] = 1\nparams[\"film_parameter_MLP_hidden_layers\"] = 1\n\n#params[\"num_edge_MLP_hidden_layers\"] = 16\n\n#gnn layer with defined hyperparameters\ngnn_layer = GNN(params) \n\n#gnn output layer\n#outpur shape: [data_dimension,hidden layers]\ngnn_out = gnn_layer(gnn_input)\n\nprint('gnn_out', gnn_out)           \n\n#calculating segmented mean based on segment_ids\navg = segment_mean(\n    data=gnn_out,\n    segment_ids=node2graph\n    )\n\nprint('mean:', avg)\n\n#final dense layer with sigmoid\n#Output [None,8]\nfc1 = Dense(256,activation='relu')(avg)\nfc2 = Dense(128,activation='relu')(fc1)\nfc3 = Dense(64,activation='relu')(fc2)\n# d1 = Dropout(0.2)(fc2)\n\n#output shape: [batch_size,1] \npred = Dense(1, activation='sigmoid')(fc3)\nprint('pred:', pred)\n\n#Building The Model \n#inputs is dictionary of data, edges, node2graph\n#output: prediction value from dense layer\nmodel_7 = Model(\n    inputs={\n        'data': data, \n        'edges': edge,\n        'node2grah': node2graph,\n    },\n    outputs=pred\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T00:07:04.146403Z","iopub.execute_input":"2023-04-28T00:07:04.147091Z","iopub.status.idle":"2023-04-28T00:07:06.304925Z","shell.execute_reply.started":"2023-04-28T00:07:04.147041Z","shell.execute_reply":"2023-04-28T00:07:06.303456Z"},"trusted":true},"execution_count":132,"outputs":[{"name":"stdout","text":"gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 40), dtype=tf.float32, name=None), name='gnn_21/StatefulPartitionedCall:0', description=\"created by layer 'gnn_21'\")\nmean: KerasTensor(type_spec=TensorSpec(shape=(None, 40), dtype=tf.float32, name=None), name='tf.math.segment_mean_12/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_12'\")\npred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_31/Sigmoid:0', description=\"created by layer 'dense_31'\")\n","output_type":"stream"}]},{"cell_type":"code","source":"#printing summary of the model\nmodel_7.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-28T00:07:06.307182Z","iopub.execute_input":"2023-04-28T00:07:06.307639Z","iopub.status.idle":"2023-04-28T00:07:06.352450Z","shell.execute_reply.started":"2023-04-28T00:07:06.307597Z","shell.execute_reply":"2023-04-28T00:07:06.350532Z"},"trusted":true},"execution_count":133,"outputs":[{"name":"stdout","text":"Model: \"model_12\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_66 (InputLayer)          [(None,)]            0           []                               \n                                                                                                  \n input_64 (InputLayer)          [(None,)]            0           []                               \n                                                                                                  \n tf.math.reduce_max_21 (TFOpLam  ()                  0           ['input_66[0][0]']               \n bda)                                                                                             \n                                                                                                  \n embedding_21 (Embedding)       (None, 70)           35000       ['input_64[0][0]']               \n                                                                                                  \n input_65 (InputLayer)          [(None, 2)]          0           []                               \n                                                                                                  \n tf.__operators__.add_21 (TFOpL  ()                  0           ['tf.math.reduce_max_21[0][0]']  \n ambda)                                                                                           \n                                                                                                  \n gnn_21 (GNN)                   (None, 40)           50240       ['embedding_21[0][0]',           \n                                                                  'input_65[0][0]',               \n                                                                  'input_66[0][0]',               \n                                                                  'tf.__operators__.add_21[0][0]']\n                                                                                                  \n tf.math.segment_mean_12 (TFOpL  (None, 40)          0           ['gnn_21[0][0]',                 \n ambda)                                                           'input_66[0][0]']               \n                                                                                                  \n dense_28 (Dense)               (None, 256)          10496       ['tf.math.segment_mean_12[0][0]']\n                                                                                                  \n dense_29 (Dense)               (None, 128)          32896       ['dense_28[0][0]']               \n                                                                                                  \n dense_30 (Dense)               (None, 64)           8256        ['dense_29[0][0]']               \n                                                                                                  \n dense_31 (Dense)               (None, 1)            65          ['dense_30[0][0]']               \n                                                                                                  \n==================================================================================================\nTotal params: 136,953\nTrainable params: 136,953\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"\n#compile the model by using my adam optimizer and BinaryCrossentropy loss\nmodel_7.compile(\n    optimizer = 'adam', \n    loss='BinaryCrossentropy',\n    metrics=['AUC']\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T00:07:07.514371Z","iopub.execute_input":"2023-04-28T00:07:07.514955Z","iopub.status.idle":"2023-04-28T00:07:07.532714Z","shell.execute_reply.started":"2023-04-28T00:07:07.514909Z","shell.execute_reply":"2023-04-28T00:07:07.531349Z"},"trusted":true},"execution_count":134,"outputs":[]},{"cell_type":"code","source":"%%time\nbatch_size = 32\n#math.ceil: returns the smallest integral value greater than the number\n#no. of batches for training data\nnum_batchs = math.ceil(len(training_set) / batch_size)\n#no. of batches for validation data\nnum_batchs_validation = math.ceil(len(validation_set) / batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T00:08:04.789273Z","iopub.execute_input":"2023-04-28T00:08:04.789758Z","iopub.status.idle":"2023-04-28T00:08:04.798264Z","shell.execute_reply.started":"2023-04-28T00:08:04.789715Z","shell.execute_reply":"2023-04-28T00:08:04.796958Z"},"trusted":true},"execution_count":137,"outputs":[{"name":"stdout","text":"CPU times: user 13 s, sys: 1e+03 ns, total: 14 s\nWall time: 18.6 s\n","output_type":"stream"}]},{"cell_type":"code","source":"#fit the models with 30 epoch and no early stopping\nhist = model_7.fit(\n    gen_batch(\n        training_set, batch_size=batch_size, repeat=True\n    ),\n    steps_per_epoch=num_batchs,\n    epochs=30,\n    validation_data=gen_batch(\n        validation_set, batch_size=32, repeat=True\n    ),\n    validation_steps=num_batchs_validation,\n    verbose=1\n)\nprint(hist)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T00:08:06.163674Z","iopub.execute_input":"2023-04-28T00:08:06.164152Z","iopub.status.idle":"2023-04-28T00:34:58.364615Z","shell.execute_reply.started":"2023-04-28T00:08:06.164111Z","shell.execute_reply":"2023-04-28T00:34:58.363049Z"},"trusted":true},"execution_count":138,"outputs":[{"name":"stdout","text":"Epoch 1/30\n1265/1265 [==============================] - 54s 43ms/step - loss: 0.6063 - auc: 0.7299 - val_loss: 0.5957 - val_auc: 0.7527\nEpoch 2/30\n1265/1265 [==============================] - 53s 42ms/step - loss: 0.5872 - auc: 0.7528 - val_loss: 0.5632 - val_auc: 0.7772\nEpoch 3/30\n1265/1265 [==============================] - 53s 42ms/step - loss: 0.5644 - auc: 0.7754 - val_loss: 0.5548 - val_auc: 0.7923\nEpoch 4/30\n1265/1265 [==============================] - 55s 44ms/step - loss: 0.5495 - auc: 0.7924 - val_loss: 0.5355 - val_auc: 0.8137\nEpoch 5/30\n1265/1265 [==============================] - 53s 42ms/step - loss: 0.5301 - auc: 0.8122 - val_loss: 0.5133 - val_auc: 0.8327\nEpoch 6/30\n1265/1265 [==============================] - 54s 43ms/step - loss: 0.5101 - auc: 0.8294 - val_loss: 0.4879 - val_auc: 0.8481\nEpoch 7/30\n1265/1265 [==============================] - 56s 44ms/step - loss: 0.4920 - auc: 0.8430 - val_loss: 0.4617 - val_auc: 0.8642\nEpoch 8/30\n1265/1265 [==============================] - 53s 42ms/step - loss: 0.4780 - auc: 0.8527 - val_loss: 0.4551 - val_auc: 0.8709\nEpoch 9/30\n1265/1265 [==============================] - 54s 42ms/step - loss: 0.4629 - auc: 0.8630 - val_loss: 0.4457 - val_auc: 0.8738\nEpoch 10/30\n1265/1265 [==============================] - 55s 43ms/step - loss: 0.4454 - auc: 0.8738 - val_loss: 0.4295 - val_auc: 0.8845\nEpoch 11/30\n1265/1265 [==============================] - 53s 42ms/step - loss: 0.4303 - auc: 0.8826 - val_loss: 0.4143 - val_auc: 0.8973\nEpoch 12/30\n1265/1265 [==============================] - 54s 42ms/step - loss: 0.4092 - auc: 0.8944 - val_loss: 0.4036 - val_auc: 0.9048\nEpoch 13/30\n1265/1265 [==============================] - 53s 42ms/step - loss: 0.3914 - auc: 0.9032 - val_loss: 0.3632 - val_auc: 0.9183\nEpoch 14/30\n1265/1265 [==============================] - 53s 42ms/step - loss: 0.3700 - auc: 0.9137 - val_loss: 0.3721 - val_auc: 0.9187\nEpoch 15/30\n1265/1265 [==============================] - 53s 42ms/step - loss: 0.3511 - auc: 0.9214 - val_loss: 0.3234 - val_auc: 0.9329\nEpoch 16/30\n1265/1265 [==============================] - 56s 44ms/step - loss: 0.3503 - auc: 0.9217 - val_loss: 0.3365 - val_auc: 0.9256\nEpoch 17/30\n1265/1265 [==============================] - 52s 41ms/step - loss: 0.3345 - auc: 0.9276 - val_loss: 0.3041 - val_auc: 0.9389\nEpoch 18/30\n1265/1265 [==============================] - 55s 44ms/step - loss: 0.3197 - auc: 0.9338 - val_loss: 0.3187 - val_auc: 0.9340\nEpoch 19/30\n1265/1265 [==============================] - 52s 41ms/step - loss: 0.3069 - auc: 0.9384 - val_loss: 0.2833 - val_auc: 0.9465\nEpoch 20/30\n1265/1265 [==============================] - 52s 41ms/step - loss: 0.2888 - auc: 0.9448 - val_loss: 0.2723 - val_auc: 0.9506\nEpoch 21/30\n1265/1265 [==============================] - 52s 41ms/step - loss: 0.2869 - auc: 0.9463 - val_loss: 0.2810 - val_auc: 0.9467\nEpoch 22/30\n1265/1265 [==============================] - 52s 41ms/step - loss: 0.2660 - auc: 0.9528 - val_loss: 0.2475 - val_auc: 0.9568\nEpoch 23/30\n1265/1265 [==============================] - 55s 43ms/step - loss: 0.2603 - auc: 0.9550 - val_loss: 0.2591 - val_auc: 0.9554\nEpoch 24/30\n1265/1265 [==============================] - 53s 42ms/step - loss: 0.2479 - auc: 0.9585 - val_loss: 0.2528 - val_auc: 0.9566\nEpoch 25/30\n1265/1265 [==============================] - 55s 44ms/step - loss: 0.2455 - auc: 0.9598 - val_loss: 0.2311 - val_auc: 0.9610\nEpoch 26/30\n1265/1265 [==============================] - 54s 43ms/step - loss: 0.2395 - auc: 0.9624 - val_loss: 0.2605 - val_auc: 0.9558\nEpoch 27/30\n1265/1265 [==============================] - 52s 41ms/step - loss: 0.2228 - auc: 0.9659 - val_loss: 0.2145 - val_auc: 0.9670\nEpoch 28/30\n1265/1265 [==============================] - 54s 43ms/step - loss: 0.2173 - auc: 0.9681 - val_loss: 0.2400 - val_auc: 0.9644\nEpoch 29/30\n1265/1265 [==============================] - 54s 43ms/step - loss: 0.2156 - auc: 0.9684 - val_loss: 0.1923 - val_auc: 0.9729\nEpoch 30/30\n1265/1265 [==============================] - 55s 43ms/step - loss: 0.2133 - auc: 0.9692 - val_loss: 0.2005 - val_auc: 0.9717\n<keras.callbacks.History object at 0x7885f6550890>\n","output_type":"stream"}]},{"cell_type":"code","source":"#make a prediction by using the model\ny_pred_7 = model_7.predict(\n    gen_batch(testing_set, batch_size=32, shuffle=False)\n)\ny_pred_7 = np.reshape(y_pred_7, -1)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T00:35:05.209049Z","iopub.execute_input":"2023-04-28T00:35:05.209483Z","iopub.status.idle":"2023-04-28T00:35:10.539207Z","shell.execute_reply.started":"2023-04-28T00:35:05.209446Z","shell.execute_reply":"2023-04-28T00:35:10.537782Z"},"trusted":true},"execution_count":139,"outputs":[{"name":"stdout","text":"386/386 [==============================] - 5s 12ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"#make a submission file to upload it on kaggle\nsubmission = pd.DataFrame({'label':y_pred_7})\nsubmission.index.name = 'id'\nsubmission.to_csv('trial_7.csv')\n\n#Kaggle==> 0.8339","metadata":{"execution":{"iopub.status.busy":"2023-04-28T00:35:10.542174Z","iopub.execute_input":"2023-04-28T00:35:10.542563Z","iopub.status.idle":"2023-04-28T00:35:10.580713Z","shell.execute_reply.started":"2023-04-28T00:35:10.542526Z","shell.execute_reply":"2023-04-28T00:35:10.579120Z"},"trusted":true},"execution_count":140,"outputs":[]},{"cell_type":"markdown","source":"**Expectation:**\n\nThe hyperparameters for the GNN layer are defined with a relational graph convolutional network (RGCN) message-passing algorithm, a hidden dimension of 40, 2 hidden layers for the edge and aggregation MLP, 8 attention heads, 4 layers, and a dense layer every 1 layer. The Embedding layer is set to embed each token as a 70-size vector. The final dense layer consists of three hidden dense layers with 256, 128, and 64 units, respectively. The input and output layers are combined into a Model instance.\n\n**I expect it will give me accuracy around 82**\n\n**Observation:**\n\nMy model got a score of 0.8339 on kaggle\n\n**Plan**\n\nI will change my hyperparameters to :\n\nparams[\"message_calculation_class\"] = 'GNN_FiLM'\n\nparams[\"hidden_dim\"] = 40\n\nparams[\"num_aggr_MLP_hidden_layers\"] = 2\n\nparams[\"num_edge_MLP_hidden_layers\"] = 2\n\nparams[\"num_heads\"] = 8\n\nparams[\"num_layers\"] = 4\n\nparams[\"dense_every_num_layers\"] = 1\n\nparams[\"film_parameter_MLP_hidden_layers\"] = 1","metadata":{}},{"cell_type":"markdown","source":"# Trial_8 GNN-FiLM","metadata":{}},{"cell_type":"code","source":"#Input layer for nodes (tokenized text data)\ndata = keras.Input(batch_shape=(None,))\n\n# the first dim is different to the previous one. it is the total number of edges in this batch\n#Input layer for edge data\nedge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n#Input layer for node2graph ids\nnode2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n\n#embedding layer over data with each token embedded as a vector   size vector eg. [440,75]\nembeded = Embedding(tokenizer.num_words, 80)(data)\n\n# number of graphs (number of samples)\n#calculating number of samples (or min(batch_size,no._of_samples))\nnum_graph = tf.reduce_max(node2graph)+1  \n\n#gnn_input layer with inputs as defined above\ngnn_input = GNNInput(\n    node_features=embeded,\n    adjacency_lists=(edge,),\n    node_to_graph_map=node2graph, \n    num_graphs=num_graph,\n)\n\n#defining hyperparameters for GNN layer\nparams = GNN.get_default_hyperparameters()\n#defining hidden dimension of the gnn layer\n\nparams[\"message_calculation_class\"] = 'GNN_FiLM'\nparams[\"hidden_dim\"] = 40\nparams[\"num_aggr_MLP_hidden_layers\"] = 2\nparams[\"num_edge_MLP_hidden_layers\"] = 2\nparams[\"num_heads\"] = 8\nparams[\"num_layers\"] = 4\nparams[\"dense_every_num_layers\"] = 1\nparams[\"film_parameter_MLP_hidden_layers\"] = 1\n\n\n\n#gnn layer with defined hyperparameters\ngnn_layer = GNN(params) \n\n#gnn output layer\n#outpur shape: [data_dimension,hidden layers]\ngnn_out = gnn_layer(gnn_input)\n\nprint('gnn_out', gnn_out)           \n\n#calculating segmented mean based on segment_ids\navg = segment_mean(\n    data=gnn_out,\n    segment_ids=node2graph\n    )\n\nprint('mean:', avg)\n\n#final dense layer with sigmoid\n#Output [None,8]\nfc1 = Dense(64,activation='relu')(avg)\nfc2 = Dense(32,activation='relu')(fc1)\n# d1 = Dropout(0.2)(fc2)\n\n#output shape: [batch_size,1] \npred = Dense(1, activation='sigmoid')(fc2)\nprint('pred:', pred)\n\n#Building The Model \n#inputs is dictionary of data, edges, node2graph\n#output: prediction value from dense layer\nmodel_8 = Model(\n    inputs={\n        'data': data, \n        'edges': edge,\n        'node2grah': node2graph,\n    },\n    outputs=pred\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T00:36:07.836875Z","iopub.execute_input":"2023-04-28T00:36:07.837357Z","iopub.status.idle":"2023-04-28T00:36:08.866480Z","shell.execute_reply.started":"2023-04-28T00:36:07.837316Z","shell.execute_reply":"2023-04-28T00:36:08.865145Z"},"trusted":true},"execution_count":141,"outputs":[{"name":"stdout","text":"gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 40), dtype=tf.float32, name=None), name='gnn_22/StatefulPartitionedCall:0', description=\"created by layer 'gnn_22'\")\nmean: KerasTensor(type_spec=TensorSpec(shape=(None, 40), dtype=tf.float32, name=None), name='tf.math.segment_mean_13/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_13'\")\npred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_34/Sigmoid:0', description=\"created by layer 'dense_34'\")\n","output_type":"stream"}]},{"cell_type":"code","source":"#printing summary of the model\nmodel_8.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-28T00:36:09.379781Z","iopub.execute_input":"2023-04-28T00:36:09.380255Z","iopub.status.idle":"2023-04-28T00:36:09.447452Z","shell.execute_reply.started":"2023-04-28T00:36:09.380214Z","shell.execute_reply":"2023-04-28T00:36:09.446096Z"},"trusted":true},"execution_count":142,"outputs":[{"name":"stdout","text":"Model: \"model_13\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_69 (InputLayer)          [(None,)]            0           []                               \n                                                                                                  \n input_67 (InputLayer)          [(None,)]            0           []                               \n                                                                                                  \n tf.math.reduce_max_22 (TFOpLam  ()                  0           ['input_69[0][0]']               \n bda)                                                                                             \n                                                                                                  \n embedding_22 (Embedding)       (None, 80)           40000       ['input_67[0][0]']               \n                                                                                                  \n input_68 (InputLayer)          [(None, 2)]          0           []                               \n                                                                                                  \n tf.__operators__.add_22 (TFOpL  ()                  0           ['tf.math.reduce_max_22[0][0]']  \n ambda)                                                                                           \n                                                                                                  \n gnn_22 (GNN)                   (None, 40)           89040       ['embedding_22[0][0]',           \n                                                                  'input_68[0][0]',               \n                                                                  'input_69[0][0]',               \n                                                                  'tf.__operators__.add_22[0][0]']\n                                                                                                  \n tf.math.segment_mean_13 (TFOpL  (None, 40)          0           ['gnn_22[0][0]',                 \n ambda)                                                           'input_69[0][0]']               \n                                                                                                  \n dense_32 (Dense)               (None, 64)           2624        ['tf.math.segment_mean_13[0][0]']\n                                                                                                  \n dense_33 (Dense)               (None, 32)           2080        ['dense_32[0][0]']               \n                                                                                                  \n dense_34 (Dense)               (None, 1)            33          ['dense_33[0][0]']               \n                                                                                                  \n==================================================================================================\nTotal params: 133,777\nTrainable params: 133,777\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"#compile the model by using adam optimizer and BinaryCrossentropy loss\nmodel_8.compile(\n    optimizer = 'adam', \n    loss='BinaryCrossentropy',\n    metrics=['AUC']\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T00:36:10.856937Z","iopub.execute_input":"2023-04-28T00:36:10.857381Z","iopub.status.idle":"2023-04-28T00:36:10.875409Z","shell.execute_reply.started":"2023-04-28T00:36:10.857344Z","shell.execute_reply":"2023-04-28T00:36:10.874237Z"},"trusted":true},"execution_count":143,"outputs":[]},{"cell_type":"code","source":"%%time\nbatch_size = 32\n#math.ceil: returns the smallest integral value greater than the number\n#no. of batches for training data\nnum_batchs = math.ceil(len(training_set) / batch_size)\n#no. of batches for validation data\nnum_batchs_validation = math.ceil(len(validation_set) / batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T00:36:52.398874Z","iopub.execute_input":"2023-04-28T00:36:52.400120Z","iopub.status.idle":"2023-04-28T00:36:52.407190Z","shell.execute_reply.started":"2023-04-28T00:36:52.400059Z","shell.execute_reply":"2023-04-28T00:36:52.405865Z"},"trusted":true},"execution_count":146,"outputs":[{"name":"stdout","text":"CPU times: user 11 s, sys: 0 ns, total: 11 s\nWall time: 17.4 s\n","output_type":"stream"}]},{"cell_type":"code","source":"#fit the models with 30 epoch and using early stopping to avoid overfitting\nhist = model_8.fit(\n    gen_batch(\n        training_set, batch_size=batch_size, repeat=True\n    ),\n    steps_per_epoch=num_batchs,\n    epochs=30,\n    validation_data=gen_batch(\n        validation_set, batch_size=32, repeat=True\n    ),\n    validation_steps=num_batchs_validation,\n  #  callbacks=tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 3),\n    # verbose=1\n)\nprint(hist)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T00:36:53.387114Z","iopub.execute_input":"2023-04-28T00:36:53.387525Z","iopub.status.idle":"2023-04-28T01:09:15.425454Z","shell.execute_reply.started":"2023-04-28T00:36:53.387489Z","shell.execute_reply":"2023-04-28T01:09:15.423777Z"},"trusted":true},"execution_count":147,"outputs":[{"name":"stdout","text":"Epoch 1/30\n1265/1265 [==============================] - 64s 50ms/step - loss: 0.5909 - auc: 0.7489 - val_loss: 0.5413 - val_auc: 0.8048\nEpoch 2/30\n1265/1265 [==============================] - 65s 52ms/step - loss: 0.5246 - auc: 0.8177 - val_loss: 0.4825 - val_auc: 0.8510\nEpoch 3/30\n1265/1265 [==============================] - 64s 51ms/step - loss: 0.4840 - auc: 0.8484 - val_loss: 0.4833 - val_auc: 0.8577\nEpoch 4/30\n1265/1265 [==============================] - 66s 52ms/step - loss: 0.4558 - auc: 0.8674 - val_loss: 0.4575 - val_auc: 0.8819\nEpoch 5/30\n1265/1265 [==============================] - 64s 51ms/step - loss: 0.4269 - auc: 0.8853 - val_loss: 0.3968 - val_auc: 0.9051\nEpoch 6/30\n1265/1265 [==============================] - 65s 51ms/step - loss: 0.3910 - auc: 0.9044 - val_loss: 0.3672 - val_auc: 0.9161\nEpoch 7/30\n1265/1265 [==============================] - 63s 50ms/step - loss: 0.3746 - auc: 0.9128 - val_loss: 0.3543 - val_auc: 0.9224\nEpoch 8/30\n1265/1265 [==============================] - 65s 51ms/step - loss: 0.3505 - auc: 0.9235 - val_loss: 0.3289 - val_auc: 0.9331\nEpoch 9/30\n1265/1265 [==============================] - 63s 50ms/step - loss: 0.3292 - auc: 0.9328 - val_loss: 0.3348 - val_auc: 0.9335\nEpoch 10/30\n1265/1265 [==============================] - 62s 49ms/step - loss: 0.3181 - auc: 0.9370 - val_loss: 0.3162 - val_auc: 0.9385\nEpoch 11/30\n1265/1265 [==============================] - 65s 51ms/step - loss: 0.2957 - auc: 0.9449 - val_loss: 0.3076 - val_auc: 0.9398\nEpoch 12/30\n1265/1265 [==============================] - 63s 50ms/step - loss: 0.2818 - auc: 0.9490 - val_loss: 0.2737 - val_auc: 0.9535\nEpoch 13/30\n1265/1265 [==============================] - 65s 51ms/step - loss: 0.2660 - auc: 0.9545 - val_loss: 0.2656 - val_auc: 0.9563\nEpoch 14/30\n1265/1265 [==============================] - 65s 51ms/step - loss: 0.2595 - auc: 0.9565 - val_loss: 0.2579 - val_auc: 0.9557\nEpoch 15/30\n1265/1265 [==============================] - 62s 49ms/step - loss: 0.2394 - auc: 0.9623 - val_loss: 0.2359 - val_auc: 0.9606\nEpoch 16/30\n1265/1265 [==============================] - 63s 50ms/step - loss: 0.2307 - auc: 0.9644 - val_loss: 0.2098 - val_auc: 0.9680\nEpoch 17/30\n1265/1265 [==============================] - 63s 50ms/step - loss: 0.2218 - auc: 0.9667 - val_loss: 0.2265 - val_auc: 0.9653\nEpoch 18/30\n1265/1265 [==============================] - 63s 50ms/step - loss: 0.2167 - auc: 0.9677 - val_loss: 0.2022 - val_auc: 0.9712\nEpoch 19/30\n1265/1265 [==============================] - 63s 50ms/step - loss: 0.2091 - auc: 0.9699 - val_loss: 0.1985 - val_auc: 0.9717\nEpoch 20/30\n1265/1265 [==============================] - 63s 49ms/step - loss: 0.1964 - auc: 0.9726 - val_loss: 0.1930 - val_auc: 0.9715\nEpoch 21/30\n1265/1265 [==============================] - 65s 51ms/step - loss: 0.4864 - auc: 0.8426 - val_loss: 0.5318 - val_auc: 0.8110\nEpoch 22/30\n1265/1265 [==============================] - 63s 50ms/step - loss: 0.5148 - auc: 0.8262 - val_loss: 0.4913 - val_auc: 0.8472\nEpoch 23/30\n1265/1265 [==============================] - 63s 50ms/step - loss: 0.5074 - auc: 0.8314 - val_loss: 0.4834 - val_auc: 0.8515\nEpoch 24/30\n1265/1265 [==============================] - 65s 52ms/step - loss: 0.4793 - auc: 0.8521 - val_loss: 0.4702 - val_auc: 0.8582\nEpoch 25/30\n1265/1265 [==============================] - 65s 51ms/step - loss: 0.4647 - auc: 0.8614 - val_loss: 0.4419 - val_auc: 0.8785\nEpoch 26/30\n1265/1265 [==============================] - 63s 50ms/step - loss: 0.4720 - auc: 0.8569 - val_loss: 0.4558 - val_auc: 0.8702\nEpoch 27/30\n1265/1265 [==============================] - 63s 50ms/step - loss: 0.4569 - auc: 0.8665 - val_loss: 0.4278 - val_auc: 0.8857\nEpoch 28/30\n1265/1265 [==============================] - 64s 51ms/step - loss: 0.4353 - auc: 0.8798 - val_loss: 0.4249 - val_auc: 0.8858\nEpoch 29/30\n1265/1265 [==============================] - 63s 50ms/step - loss: 0.4257 - auc: 0.8851 - val_loss: 0.4090 - val_auc: 0.8961\nEpoch 30/30\n1265/1265 [==============================] - 62s 49ms/step - loss: 0.4220 - auc: 0.8869 - val_loss: 0.4139 - val_auc: 0.8938\n<keras.callbacks.History object at 0x78862df9cd50>\n","output_type":"stream"}]},{"cell_type":"code","source":"#make a prediction by using the model\ny_pred_8 = model_8.predict(\n    gen_batch(testing_set, batch_size=32, shuffle=False)\n)\ny_pred_8 = np.reshape(y_pred_8, -1)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T01:09:15.427842Z","iopub.execute_input":"2023-04-28T01:09:15.428723Z","iopub.status.idle":"2023-04-28T01:09:21.522419Z","shell.execute_reply.started":"2023-04-28T01:09:15.428672Z","shell.execute_reply":"2023-04-28T01:09:21.520613Z"},"trusted":true},"execution_count":148,"outputs":[{"name":"stdout","text":"386/386 [==============================] - 6s 14ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"#make a submission file to upload it on kaggle\nsubmission = pd.DataFrame({'label':y_pred_8})\nsubmission.index.name = 'id'\nsubmission.to_csv('trial_8_GNN_FiLM.csv')\n# 0.86","metadata":{"execution":{"iopub.status.busy":"2023-04-28T01:09:21.526133Z","iopub.execute_input":"2023-04-28T01:09:21.526716Z","iopub.status.idle":"2023-04-28T01:09:21.562661Z","shell.execute_reply.started":"2023-04-28T01:09:21.526658Z","shell.execute_reply":"2023-04-28T01:09:21.561462Z"},"trusted":true},"execution_count":149,"outputs":[]},{"cell_type":"markdown","source":"**Expectation:**\n\nhe hyperparameters for the GNN layer are defined with a GNN Feature-wise Linear Modulation (GNN_FiLM) message-passing algorithm, a hidden dimension of 40, 2 hidden layers for the edge and aggregation MLP, 8 attention heads, 4 layers, and a dense layer every 1 layer. The Embedding layer is set to embed each token as an 80-size vector. The final dense layer consists of two hidden dense layers with 64 and 32 units, respectively. The input and output layers are combined into a Model instance.\n\n**I expect it will give me accuracy around 85**\n\n**Observation:**\n\nMy model got a score of 0.86 on kaggle\n\n**Plan**\n\nI will change my hyperparameters to :\n\n\nparams[\"hidden_dim\"] = 64 \n\nparams[\"message_calculation_class\"] = 'gnn_edge_mlp'\n\nparams[\"num_aggr_MLP_hidden_layers\"] = 4\n\n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Trail_9 gnn_edge_mlp","metadata":{}},{"cell_type":"code","source":"#importing libraries\nimport tensorflow as tf\nfrom tensorflow.math import segment_mean \nfrom tensorflow import keras\nfrom tensorflow.keras import Input, Model \nfrom tensorflow.keras.layers import Embedding, Dense \nfrom tensorflow.keras.optimizers import Adam \n\n#identify the 4 GNNInput inputs(data, edge, node2graph, num_graph)\ndata = keras.Input(batch_shape=(None,))                           #Input layer for nodes (tokenized text data)            \nembeded = Embedding(tokenizer.num_words, 100)(data)               #embedding layer over data with each token embedded as  size vector \n# the first dim is different to the previous one. it is the total number of edges in this batch\nedge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)         #Input layer for edge data         \nnode2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)     #Input layer for node2graph ids    \n# number of graphs (number of samples)\nnum_graph = tf.reduce_max(node2graph)+1                           #number of graphs (number of samples) \n\n#gnn_input layer with inputs as defined above\ngnn_input = GNNInput(\n    node_features=embeded,\n    adjacency_lists=(edge,),\n    node_to_graph_map=node2graph, \n    num_graphs=num_graph,\n)\n\n# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n#defining hyperparameters for GNN layer\nparams = GNN.get_default_hyperparameters()\nparams[\"hidden_dim\"] = 64 \n#defining hidden dimension of the gnn layer(the output of all message passing layers)                   \nparams[\"message_calculation_class\"] = 'gnn_edge_mlp'\nparams[\"num_aggr_MLP_hidden_layers\"] = 4\n\n#gnn layer with defined hyperparameters\ngnn_layer = GNN(params)  \n\n#gnn output layer \ngnn_out = gnn_layer(gnn_input) \nprint('gnn_out', gnn_out)           \n\n# https://www.tensorflow.org/api_docs/python/tf/math/segment_mean\n\n#calculating segmented mean based on segment_ids\navg = segment_mean(\n    data=gnn_out,\n    segment_ids=node2graph\n    )                                     \nprint('mean:', avg)\n\n#final dense layer with sigmoid activation function\npred = Dense(1, activation='sigmoid')(avg)    \nprint('pred:', pred)\n\n#building model \n# input : dictionary of data,edges and node2graph\n# output: prediction value from dense layer\n\nmodel_9 = Model(\n    inputs={\n        'data': data, \n        'edges': edge,\n        'node2grah': node2graph,\n    },\n    outputs=pred\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-28T22:13:21.540510Z","iopub.execute_input":"2023-04-28T22:13:21.542274Z","iopub.status.idle":"2023-04-28T22:13:22.358234Z","shell.execute_reply.started":"2023-04-28T22:13:21.542210Z","shell.execute_reply":"2023-04-28T22:13:22.356393Z"},"trusted":true},"execution_count":70,"outputs":[{"name":"stdout","text":"gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='gnn_9/StatefulPartitionedCall:0', description=\"created by layer 'gnn_9'\")\nmean: KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='tf.math.segment_mean_6/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_6'\")\npred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_16/Sigmoid:0', description=\"created by layer 'dense_16'\")\n","output_type":"stream"}]},{"cell_type":"code","source":"model_9.summary() #display model's sumarry","metadata":{"execution":{"iopub.status.busy":"2023-04-28T22:13:24.026519Z","iopub.execute_input":"2023-04-28T22:13:24.026950Z","iopub.status.idle":"2023-04-28T22:13:24.071915Z","shell.execute_reply.started":"2023-04-28T22:13:24.026917Z","shell.execute_reply":"2023-04-28T22:13:24.070207Z"},"trusted":true},"execution_count":71,"outputs":[{"name":"stdout","text":"Model: \"model_6\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_30 (InputLayer)          [(None,)]            0           []                               \n                                                                                                  \n input_28 (InputLayer)          [(None,)]            0           []                               \n                                                                                                  \n tf.math.reduce_max_9 (TFOpLamb  ()                  0           ['input_30[0][0]']               \n da)                                                                                              \n                                                                                                  \n embedding_9 (Embedding)        (None, 100)          50000       ['input_28[0][0]']               \n                                                                                                  \n input_29 (InputLayer)          [(None, 2)]          0           []                               \n                                                                                                  \n tf.__operators__.add_9 (TFOpLa  ()                  0           ['tf.math.reduce_max_9[0][0]']   \n mbda)                                                                                            \n                                                                                                  \n gnn_9 (GNN)                    (None, 64)           76672       ['embedding_9[0][0]',            \n                                                                  'input_29[0][0]',               \n                                                                  'input_30[0][0]',               \n                                                                  'tf.__operators__.add_9[0][0]'] \n                                                                                                  \n tf.math.segment_mean_6 (TFOpLa  (None, 64)          0           ['gnn_9[0][0]',                  \n mbda)                                                            'input_30[0][0]']               \n                                                                                                  \n dense_16 (Dense)               (None, 1)            65          ['tf.math.segment_mean_6[0][0]'] \n                                                                                                  \n==================================================================================================\nTotal params: 126,737\nTrainable params: 126,737\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model_9.compile( #The compilation is performed using one single method call called compile() as it shows\n    loss='BinaryCrossentropy', #loss parameter\n    metrics=['AUC'] #metrics parameter\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T22:13:25.333816Z","iopub.execute_input":"2023-04-28T22:13:25.334674Z","iopub.status.idle":"2023-04-28T22:13:25.353061Z","shell.execute_reply.started":"2023-04-28T22:13:25.334628Z","shell.execute_reply":"2023-04-28T22:13:25.351631Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"%%time\nbatch_size = 32\n#math.ceil: returns the smallest integral value greater than the number\n#no. of batches for training data\nnum_batchs = math.ceil(len(training_set) / batch_size)\n#no. of batches for validation data\nnum_batchs_validation = math.ceil(len(validation_set) / batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T22:13:27.519654Z","iopub.execute_input":"2023-04-28T22:13:27.520101Z","iopub.status.idle":"2023-04-28T22:13:27.527365Z","shell.execute_reply.started":"2023-04-28T22:13:27.520064Z","shell.execute_reply":"2023-04-28T22:13:27.525941Z"},"trusted":true},"execution_count":73,"outputs":[{"name":"stdout","text":"CPU times: user 15 s, sys: 1e+03 ns, total: 16 s\nWall time: 21.5 s\n","output_type":"stream"}]},{"cell_type":"code","source":"#fit the models with 30 epoch and using early stopping to avoid overfitting\nhist = model_9.fit(\n    gen_batch(\n        training_set, batch_size=batch_size, repeat=True\n    ),\n    steps_per_epoch=num_batchs,\n    epochs=30,\n    validation_data=gen_batch(\n        validation_set, batch_size=32, repeat=True\n    ),\n    validation_steps=num_batchs_validation,\n    # verbose=1\n)\nprint(hist)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T22:13:29.061259Z","iopub.execute_input":"2023-04-28T22:13:29.061693Z","iopub.status.idle":"2023-04-28T22:46:05.303727Z","shell.execute_reply.started":"2023-04-28T22:13:29.061655Z","shell.execute_reply":"2023-04-28T22:46:05.302279Z"},"trusted":true},"execution_count":74,"outputs":[{"name":"stdout","text":"Epoch 1/30\n1265/1265 [==============================] - 70s 52ms/step - loss: 0.6369 - auc: 0.6908 - val_loss: 0.6162 - val_auc: 0.7429\nEpoch 2/30\n1265/1265 [==============================] - 66s 52ms/step - loss: 0.5934 - auc: 0.7489 - val_loss: 0.5883 - val_auc: 0.7595\nEpoch 3/30\n1265/1265 [==============================] - 68s 54ms/step - loss: 0.5687 - auc: 0.7749 - val_loss: 0.5542 - val_auc: 0.7940\nEpoch 4/30\n1265/1265 [==============================] - 67s 53ms/step - loss: 0.5472 - auc: 0.7966 - val_loss: 0.5179 - val_auc: 0.8241\nEpoch 5/30\n1265/1265 [==============================] - 63s 50ms/step - loss: 0.5286 - auc: 0.8146 - val_loss: 0.5045 - val_auc: 0.8375\nEpoch 6/30\n1265/1265 [==============================] - 62s 49ms/step - loss: 0.5126 - auc: 0.8281 - val_loss: 0.4945 - val_auc: 0.8441\nEpoch 7/30\n1265/1265 [==============================] - 64s 50ms/step - loss: 0.4995 - auc: 0.8380 - val_loss: 0.4754 - val_auc: 0.8579\nEpoch 8/30\n1265/1265 [==============================] - 67s 53ms/step - loss: 0.4899 - auc: 0.8456 - val_loss: 0.4864 - val_auc: 0.8539\nEpoch 9/30\n1265/1265 [==============================] - 67s 53ms/step - loss: 0.4771 - auc: 0.8548 - val_loss: 0.4582 - val_auc: 0.8698\nEpoch 10/30\n1265/1265 [==============================] - 66s 52ms/step - loss: 0.4647 - auc: 0.8634 - val_loss: 0.4466 - val_auc: 0.8767\nEpoch 11/30\n1265/1265 [==============================] - 66s 52ms/step - loss: 0.4571 - auc: 0.8687 - val_loss: 0.4292 - val_auc: 0.8870\nEpoch 12/30\n1265/1265 [==============================] - 65s 51ms/step - loss: 0.4466 - auc: 0.8751 - val_loss: 0.4323 - val_auc: 0.8873\nEpoch 13/30\n1265/1265 [==============================] - 65s 52ms/step - loss: 0.4396 - auc: 0.8797 - val_loss: 0.4330 - val_auc: 0.8871\nEpoch 14/30\n1265/1265 [==============================] - 71s 56ms/step - loss: 0.4308 - auc: 0.8847 - val_loss: 0.4080 - val_auc: 0.9010\nEpoch 15/30\n1265/1265 [==============================] - 75s 60ms/step - loss: 0.4244 - auc: 0.8882 - val_loss: 0.3928 - val_auc: 0.9069\nEpoch 16/30\n1265/1265 [==============================] - 66s 52ms/step - loss: 0.4197 - auc: 0.8907 - val_loss: 0.3977 - val_auc: 0.9036\nEpoch 17/30\n1265/1265 [==============================] - 66s 52ms/step - loss: 0.4120 - auc: 0.8950 - val_loss: 0.3855 - val_auc: 0.9137\nEpoch 18/30\n1265/1265 [==============================] - 66s 52ms/step - loss: 0.4052 - auc: 0.8987 - val_loss: 0.3840 - val_auc: 0.9135\nEpoch 19/30\n1265/1265 [==============================] - 66s 52ms/step - loss: 0.4023 - auc: 0.9000 - val_loss: 0.3709 - val_auc: 0.9155\nEpoch 20/30\n1265/1265 [==============================] - 68s 53ms/step - loss: 0.3984 - auc: 0.9018 - val_loss: 0.3729 - val_auc: 0.9172\nEpoch 21/30\n1265/1265 [==============================] - 63s 50ms/step - loss: 0.3946 - auc: 0.9040 - val_loss: 0.3806 - val_auc: 0.9172\nEpoch 22/30\n1265/1265 [==============================] - 63s 50ms/step - loss: 0.3867 - auc: 0.9081 - val_loss: 0.3664 - val_auc: 0.9193\nEpoch 23/30\n1265/1265 [==============================] - 61s 49ms/step - loss: 0.3811 - auc: 0.9111 - val_loss: 0.3648 - val_auc: 0.9185\nEpoch 24/30\n1265/1265 [==============================] - 63s 50ms/step - loss: 0.3763 - auc: 0.9127 - val_loss: 0.3415 - val_auc: 0.9283\nEpoch 25/30\n1265/1265 [==============================] - 61s 48ms/step - loss: 0.3701 - auc: 0.9155 - val_loss: 0.3518 - val_auc: 0.9271\nEpoch 26/30\n1265/1265 [==============================] - 61s 49ms/step - loss: 0.3662 - auc: 0.9175 - val_loss: 0.3543 - val_auc: 0.9250\nEpoch 27/30\n1265/1265 [==============================] - 61s 48ms/step - loss: 0.3651 - auc: 0.9179 - val_loss: 0.3599 - val_auc: 0.9268\nEpoch 28/30\n1265/1265 [==============================] - 61s 48ms/step - loss: 0.3531 - auc: 0.9233 - val_loss: 0.3494 - val_auc: 0.9285\nEpoch 29/30\n1265/1265 [==============================] - 65s 51ms/step - loss: 0.3571 - auc: 0.9220 - val_loss: 0.3486 - val_auc: 0.9283\nEpoch 30/30\n1265/1265 [==============================] - 65s 52ms/step - loss: 0.3543 - auc: 0.9232 - val_loss: 0.3292 - val_auc: 0.9348\n<keras.callbacks.History object at 0x7281d9116490>\n","output_type":"stream"}]},{"cell_type":"code","source":"#make a prediction by using the model\ny_pred_9 = model_9.predict(\n    gen_batch(testing_set, batch_size=32, shuffle=False)\n)\ny_pred_9 = np.reshape(y_pred_9, -1)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T22:46:16.688089Z","iopub.execute_input":"2023-04-28T22:46:16.688527Z","iopub.status.idle":"2023-04-28T22:46:23.018189Z","shell.execute_reply.started":"2023-04-28T22:46:16.688492Z","shell.execute_reply":"2023-04-28T22:46:23.016640Z"},"trusted":true},"execution_count":75,"outputs":[{"name":"stdout","text":"386/386 [==============================] - 6s 15ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"#make a submission file to upload it on kaggle\nsubmission = pd.DataFrame({'label':y_pred_9})\nsubmission.index.name = 'id'\nsubmission.to_csv('trial_9.csv')\n# kaggel =0.82","metadata":{"execution":{"iopub.status.busy":"2023-04-28T22:46:23.020610Z","iopub.execute_input":"2023-04-28T22:46:23.021175Z","iopub.status.idle":"2023-04-28T22:46:23.061672Z","shell.execute_reply.started":"2023-04-28T22:46:23.021120Z","shell.execute_reply":"2023-04-28T22:46:23.060444Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"markdown","source":"**Expectation:**\nThe hyperparameters for the GNN layer are defined with a gnn_edge_mlp message-passing algorithm, a hidden dimension of 64, and 4 hidden layers for the aggregation MLP. The Embedding layer is set to embed each token as a 100-size vector. The final dense layer consists of a single dense layer with sigmoid activation function. The input and output layers are combined into a Model instance.\n\n**I expect it will give me accuracy around 84**\n\n**Observation:**\n\nMy model got a score of 0.82 on kaggle\n\n**Plan**\n\nI will change my hyperparameters to :\n\nparams[\"hidden_dim\"] = 64\n  \nparams[\"message_calculation_class\"] = 'RGCN'","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Trail_10 RGCN","metadata":{}},{"cell_type":"code","source":"#importing tensorflow and other libraries\n#GGNN,RGCN,RGAT,RGIN,GNN-Edge-MLP,GNN-FiLM\n#import tf2_gnn.layers.message_passing.gnn_edge_mlp\nfrom  tf2_gnn.layers.message_passing import rgat,rgin,rgcn,gnn_film,ggnn,gnn_edge_mlp\nimport tensorflow as tf\nfrom tensorflow.math import segment_mean #to calculate segmented mean\nfrom tensorflow import keras\nfrom tensorflow.keras import Input, Model #layers and model\nfrom tensorflow.keras.layers import Embedding, Dense #layers\nfrom tensorflow.keras.optimizers import Adam #optimizer\n\n\n#Input layer for nodes (tokenized text data)          \ndata = keras.Input(batch_shape=(None,)) \n# the first dim is different to the previous one. it is the total number of edges in this batch\n#Input layer for edge data        \nedge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)   \n#Input layer for node2graph ids    \nnode2graph = keras.Input(batch_shape=(None,), dtype=tf.int32) \n#embedding layer over data with each token embedded as  size vector\nembeded = Embedding(tokenizer.num_words, 50)(data)  \n\n# number of graphs (number of samples)\n#calculating number of samples (or min(batch_size,no._of_samples))  \nnum_graph = tf.reduce_max(node2graph)+1  \n#gnn_input layer with inputs as defined above\ngnn_input = GNNInput(\n    node_features=embeded,\n    adjacency_lists=(edge,),\n    node_to_graph_map=node2graph, \n    num_graphs=num_graph,\n)\n\n# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n#defining hyperparameters for GNN layer\nparams = GNN.get_default_hyperparameters()\n#defining hidden dimension of the gnn layer\nparams[\"hidden_dim\"] = 64\n#Relational Graph Convolutional Networks  \nparams[\"message_calculation_class\"] = 'RGCN'\n# params[\"num_edge_MLP_hidden_layers\"] = 32\n#gnn layer with defined hyperparameters\ngnn_layer = GNN(params)  \n\n#gnn output layer \n#outpur shape: [data_dimension,hidden layers]  \ngnn_out = gnn_layer(gnn_input) \n\nprint('gnn_out', gnn_out)           \n\n# https://www.tensorflow.org/api_docs/python/tf/math/segment_mean\n\n#calculating segmented mean based on segment_ids\navg = segment_mean(\n    data=gnn_out,\n    segment_ids=node2graph\n    )#shape: [batch_size,64] \n\nprint('mean:', avg)\n\n#final dense layer with sigmoid\n#Output [None,8]\nfc1 = Dense(8,activation='LeakyReLU')(avg) \n#output shape: [batch_size,1] \npred = Dense(1, activation='sigmoid')(fc1)   \nprint('pred:', pred)\n\n#building model \n#inputs are data,edges and node2graph\n#input: dictionary\n#output: prediction value from dense layer\nmodel_10 = Model(\n    inputs={\n        'data': data, \n        'edges': edge,\n        'node2grah': node2graph,\n    },\n    outputs=pred\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T22:50:54.558604Z","iopub.execute_input":"2023-04-28T22:50:54.559091Z","iopub.status.idle":"2023-04-28T22:50:55.348681Z","shell.execute_reply.started":"2023-04-28T22:50:54.559050Z","shell.execute_reply":"2023-04-28T22:50:55.347316Z"},"trusted":true},"execution_count":82,"outputs":[{"name":"stdout","text":"gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='gnn_14/StatefulPartitionedCall:0', description=\"created by layer 'gnn_14'\")\nmean: KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='tf.math.segment_mean_8/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_8'\")\npred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_20/Sigmoid:0', description=\"created by layer 'dense_20'\")\n","output_type":"stream"}]},{"cell_type":"code","source":"model_10.summary() #display model's sumarry","metadata":{"execution":{"iopub.status.busy":"2023-04-28T22:50:55.494352Z","iopub.execute_input":"2023-04-28T22:50:55.495674Z","iopub.status.idle":"2023-04-28T22:50:55.550049Z","shell.execute_reply.started":"2023-04-28T22:50:55.495613Z","shell.execute_reply":"2023-04-28T22:50:55.548204Z"},"trusted":true},"execution_count":83,"outputs":[{"name":"stdout","text":"Model: \"model_8\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_45 (InputLayer)          [(None,)]            0           []                               \n                                                                                                  \n input_43 (InputLayer)          [(None,)]            0           []                               \n                                                                                                  \n tf.math.reduce_max_14 (TFOpLam  ()                  0           ['input_45[0][0]']               \n bda)                                                                                             \n                                                                                                  \n embedding_14 (Embedding)       (None, 50)           25000       ['input_43[0][0]']               \n                                                                                                  \n input_44 (InputLayer)          [(None, 2)]          0           []                               \n                                                                                                  \n tf.__operators__.add_14 (TFOpL  ()                  0           ['tf.math.reduce_max_14[0][0]']  \n ambda)                                                                                           \n                                                                                                  \n gnn_14 (GNN)                   (None, 64)           73472       ['embedding_14[0][0]',           \n                                                                  'input_44[0][0]',               \n                                                                  'input_45[0][0]',               \n                                                                  'tf.__operators__.add_14[0][0]']\n                                                                                                  \n tf.math.segment_mean_8 (TFOpLa  (None, 64)          0           ['gnn_14[0][0]',                 \n mbda)                                                            'input_45[0][0]']               \n                                                                                                  \n dense_19 (Dense)               (None, 8)            520         ['tf.math.segment_mean_8[0][0]'] \n                                                                                                  \n dense_20 (Dense)               (None, 1)            9           ['dense_19[0][0]']               \n                                                                                                  \n==================================================================================================\nTotal params: 99,001\nTrainable params: 99,001\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model_10.compile( #The compilation is performed using one single method call called compile() as it shows\n    loss='BinaryCrossentropy', #loss parameter\n    metrics=['AUC'] #metrics parameter\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T22:50:57.059627Z","iopub.execute_input":"2023-04-28T22:50:57.060130Z","iopub.status.idle":"2023-04-28T22:50:57.077322Z","shell.execute_reply.started":"2023-04-28T22:50:57.060090Z","shell.execute_reply":"2023-04-28T22:50:57.076140Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"%%time\nbatch_size = 32\n#math.ceil: returns the smallest integral value greater than the number\n#no. of batches for training data\nnum_batchs = math.ceil(len(training_set) / batch_size)\n#no. of batches for validation data\nnum_batchs_validation = math.ceil(len(validation_set) / batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T22:50:58.473351Z","iopub.execute_input":"2023-04-28T22:50:58.473901Z","iopub.status.idle":"2023-04-28T22:50:58.482486Z","shell.execute_reply.started":"2023-04-28T22:50:58.473850Z","shell.execute_reply":"2023-04-28T22:50:58.481295Z"},"trusted":true},"execution_count":85,"outputs":[{"name":"stdout","text":"CPU times: user 159 s, sys: 10 s, total: 169 s\nWall time: 175 s\n","output_type":"stream"}]},{"cell_type":"code","source":"#fit the models with 30 epoch and using early stopping to avoid overfitting\nhist = model_10.fit(\n    gen_batch(\n        training_set, batch_size=batch_size, repeat=True\n    ),\n    steps_per_epoch=num_batchs,\n    epochs=30,\n    validation_data=gen_batch(\n        validation_set, batch_size=32, repeat=True\n    ),\n    validation_steps=num_batchs_validation,\n    # verbose=1\n)\nprint(hist)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T22:50:59.744010Z","iopub.execute_input":"2023-04-28T22:50:59.744717Z","iopub.status.idle":"2023-04-28T23:23:23.714137Z","shell.execute_reply.started":"2023-04-28T22:50:59.744666Z","shell.execute_reply":"2023-04-28T23:23:23.712622Z"},"trusted":true},"execution_count":86,"outputs":[{"name":"stdout","text":"Epoch 1/30\n1265/1265 [==============================] - 66s 49ms/step - loss: 0.6424 - auc: 0.6753 - val_loss: 0.6270 - val_auc: 0.7323\nEpoch 2/30\n1265/1265 [==============================] - 64s 51ms/step - loss: 0.5919 - auc: 0.7488 - val_loss: 0.5719 - val_auc: 0.7772\nEpoch 3/30\n1265/1265 [==============================] - 63s 50ms/step - loss: 0.5666 - auc: 0.7771 - val_loss: 0.5539 - val_auc: 0.7968\nEpoch 4/30\n1265/1265 [==============================] - 62s 49ms/step - loss: 0.5468 - auc: 0.7963 - val_loss: 0.5372 - val_auc: 0.8185\nEpoch 5/30\n1265/1265 [==============================] - 67s 53ms/step - loss: 0.5282 - auc: 0.8144 - val_loss: 0.5109 - val_auc: 0.8327\nEpoch 6/30\n1265/1265 [==============================] - 65s 51ms/step - loss: 0.5151 - auc: 0.8259 - val_loss: 0.4880 - val_auc: 0.8493\nEpoch 7/30\n1265/1265 [==============================] - 64s 50ms/step - loss: 0.5018 - auc: 0.8363 - val_loss: 0.4800 - val_auc: 0.8549\nEpoch 8/30\n1265/1265 [==============================] - 63s 49ms/step - loss: 0.4906 - auc: 0.8446 - val_loss: 0.4812 - val_auc: 0.8574\nEpoch 9/30\n1265/1265 [==============================] - 64s 51ms/step - loss: 0.4775 - auc: 0.8542 - val_loss: 0.4707 - val_auc: 0.8624\nEpoch 10/30\n1265/1265 [==============================] - 64s 51ms/step - loss: 0.4665 - auc: 0.8617 - val_loss: 0.4488 - val_auc: 0.8783\nEpoch 11/30\n1265/1265 [==============================] - 65s 52ms/step - loss: 0.4491 - auc: 0.8732 - val_loss: 0.4321 - val_auc: 0.8830\nEpoch 12/30\n1265/1265 [==============================] - 61s 49ms/step - loss: 0.4416 - auc: 0.8777 - val_loss: 0.4571 - val_auc: 0.8752\nEpoch 13/30\n1265/1265 [==============================] - 62s 49ms/step - loss: 0.4284 - auc: 0.8857 - val_loss: 0.3992 - val_auc: 0.9016\nEpoch 14/30\n1265/1265 [==============================] - 67s 53ms/step - loss: 0.4203 - auc: 0.8902 - val_loss: 0.4134 - val_auc: 0.8949\nEpoch 15/30\n1265/1265 [==============================] - 66s 52ms/step - loss: 0.4062 - auc: 0.8977 - val_loss: 0.3709 - val_auc: 0.9172\nEpoch 16/30\n1265/1265 [==============================] - 65s 52ms/step - loss: 0.3978 - auc: 0.9023 - val_loss: 0.3753 - val_auc: 0.9141\nEpoch 17/30\n1265/1265 [==============================] - 67s 53ms/step - loss: 0.3898 - auc: 0.9060 - val_loss: 0.3700 - val_auc: 0.9163\nEpoch 18/30\n1265/1265 [==============================] - 66s 52ms/step - loss: 0.3784 - auc: 0.9114 - val_loss: 0.3619 - val_auc: 0.9206\nEpoch 19/30\n1265/1265 [==============================] - 67s 53ms/step - loss: 0.3706 - auc: 0.9151 - val_loss: 0.3576 - val_auc: 0.9291\nEpoch 20/30\n1265/1265 [==============================] - 63s 50ms/step - loss: 0.3633 - auc: 0.9186 - val_loss: 0.3972 - val_auc: 0.9197\nEpoch 21/30\n1265/1265 [==============================] - 63s 50ms/step - loss: 0.3585 - auc: 0.9210 - val_loss: 0.3273 - val_auc: 0.9354\nEpoch 22/30\n1265/1265 [==============================] - 65s 51ms/step - loss: 0.3478 - auc: 0.9253 - val_loss: 0.3138 - val_auc: 0.9385\nEpoch 23/30\n1265/1265 [==============================] - 66s 52ms/step - loss: 0.3410 - auc: 0.9283 - val_loss: 0.3140 - val_auc: 0.9386\nEpoch 24/30\n1265/1265 [==============================] - 64s 51ms/step - loss: 0.3359 - auc: 0.9303 - val_loss: 0.3017 - val_auc: 0.9427\nEpoch 25/30\n1265/1265 [==============================] - 72s 57ms/step - loss: 0.3285 - auc: 0.9333 - val_loss: 0.3232 - val_auc: 0.9362\nEpoch 26/30\n1265/1265 [==============================] - 72s 57ms/step - loss: 0.3221 - auc: 0.9356 - val_loss: 0.2879 - val_auc: 0.9470\nEpoch 27/30\n1265/1265 [==============================] - 66s 52ms/step - loss: 0.3131 - auc: 0.9392 - val_loss: 0.3067 - val_auc: 0.9428\nEpoch 28/30\n1265/1265 [==============================] - 64s 50ms/step - loss: 0.3126 - auc: 0.9393 - val_loss: 0.3051 - val_auc: 0.9457\nEpoch 29/30\n1265/1265 [==============================] - 58s 46ms/step - loss: 0.3060 - auc: 0.9418 - val_loss: 0.2858 - val_auc: 0.9484\nEpoch 30/30\n1265/1265 [==============================] - 61s 48ms/step - loss: 0.3062 - auc: 0.9419 - val_loss: 0.3015 - val_auc: 0.9457\n<keras.callbacks.History object at 0x7281d73d00d0>\n","output_type":"stream"}]},{"cell_type":"code","source":"#make a prediction by using the model\ny_pred_10 = model_10.predict(\n    gen_batch(testing_set, batch_size=32, shuffle=False)\n)\ny_pred_10 = np.reshape(y_pred_10, -1)","metadata":{"execution":{"iopub.status.busy":"2023-04-28T23:24:04.745304Z","iopub.execute_input":"2023-04-28T23:24:04.745750Z","iopub.status.idle":"2023-04-28T23:24:10.513457Z","shell.execute_reply.started":"2023-04-28T23:24:04.745715Z","shell.execute_reply":"2023-04-28T23:24:10.512033Z"},"trusted":true},"execution_count":87,"outputs":[{"name":"stdout","text":"386/386 [==============================] - 6s 14ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"#make a submission file to upload it on kaggle\nsubmission = pd.DataFrame({'label':y_pred_10})\nsubmission.index.name = 'id'\nsubmission.to_csv('trial_10_.csv')\n# 0.826","metadata":{"execution":{"iopub.status.busy":"2023-04-28T23:25:25.130379Z","iopub.execute_input":"2023-04-28T23:25:25.130876Z","iopub.status.idle":"2023-04-28T23:25:25.167017Z","shell.execute_reply.started":"2023-04-28T23:25:25.130834Z","shell.execute_reply":"2023-04-28T23:25:25.165833Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"markdown","source":"**Expectation:**\n\nThe hyperparameters for the GNN layer are defined with a RGCN message-passing algorithm, a hidden dimension of 64. The Embedding layer is set to embed each token as a 50-size vector. The final dense layer consists of a single dense layer with sigmoid activation function. The input and output layers are combined into a Model instance.\n\n**I expect it will give me accuracy around 84**\n\n**Observation:**\nMy model got a score of 0.826 on kaggle\n\n","metadata":{}},{"cell_type":"markdown","source":"# SO the best Trial , it will be trail_8\n\n**0.86 in kaggel**","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ** Answer the questions**\n\n-----------------------------\n-------------------------------","metadata":{}},{"cell_type":"markdown","source":"# **Based on the provided template, describe the format of the input file (sdf file).**\n\nThe input file is structure data file (SDF). It contains information about the chemical composition of a molecule. SDF file store information about position of individual atom in the chemical compound and also tells about the connections. Different molecules are delimited by$$$$expression.\n\n-----------------------\n\nEach sample/molecule starts with header which tells about the name/title of the compound. Other sections includes information about Atom count, version number, connections etc. Atom block tells about the elements of the compound. Bond block block tells about the bonding structure of the compound. These both blocks are used in this assignment to get information about the compound and saving them in form of edges and nodes. Each node is the atom given in the chemical molecule.","metadata":{}},{"cell_type":"markdown","source":"# **What are the input tensors to the neural network model (their meaning, not just symbol)? What is each of their dims and their meaning (e.g. batch_size)?**\n\n**The input tensors in this network are:**\n\n* data: The data contains the nodes of the chemical compound in the tokenized form. Nodes for each compound are extracted, then they are tokenized using the tokenizer and finally padding is done using pad_sequence method. The shape for each batch is [batch_size*max_len_nodes], where batch_size is the number of samples in the batch and max_len_nodes is the length of tokenized nodes after padding is done.\n\n---------------------------\n\n* edge: edge is the input tensor which carries information about connections between atoms. The shape of edge is [sum_of_all_edges,2]. The sum_of_all_edges represents the sum(no. of edges of each sample) of the batch_size. For example in a batch of 3 samples, the number of edges in sample 1: 21, sample 2: 20 and sample 3: 40. So the size of edge tensor would be [81,2].\n\n------------------------\n\n* node2graph: It is the input tensor which is used for segmented mean and contains information about segmented ids. The shape for each batch is [batch_size*max_len_nodes], where batch_size is the number of samples in the batch and max_len_nodes is the length of tokenized nodes after padding is done.\n\n---------------------\n\n","metadata":{}},{"cell_type":"markdown","source":"# **For each dim of gnn_out, what does it symbolize? For each dim of avg, what does it symbolize?**\n\n* gnn_out: The gnn_out is of shape [batch_size_node_dimension,hidden layers], where batch_size_node_dimension is the dimension of the input data (node) vector (dimension of tokenized vector for the complete batch). It represents the aggregation output of the model for each hidden layer.\n\n----------------------------\n\n* avg: Average takes the segmented mean of the gnn_out based on the segmented ids. For each sample in the batch_size, the output of gnn_out is [tokenized_vector_dimension, hidden_layers]. Each sample has one segment id. Thus the segment_mean takes the mean of all the output data in the gnn_out output and represents one sample with one number for each hidden layer. The final output of the avg tensor is of shape [batch_size, hidden_layer]. It is a way of collecting information for each sample and representing it in the form of mean data.","metadata":{}},{"cell_type":"markdown","source":"# **What is the difference between segment_mean and tf.reduce_mean? For each dim of pred, what does it symbolize?**\n\n* segment_mean takes the mean of the data which have same segmented ids.\n\n* reduce_mean: computes the mean of elements across dimensions of a tensor given the arguments.\n\nUse TensorFlow reduce_mean operation to calculate the mean of tensor elements along various dimensions of the tensor.\n\n* pred: The final output (pred) tells about the probability of a chemical compound to be active for the cancer cell or not. The shape of pred is [batch_size,1]. Thus for each sample, the final output is a number which represents the probability associated with each chemical compound about its activity.","metadata":{}},{"cell_type":"markdown","source":"# **What is the motivation/theory/idea to use multiple gcn layers comparing to just one? How many layers were used in the template?**\n\n* The default template implements the default setting of the number of layers in the gcn network.\n* The default layer are 4 as given in the documentaion.\n* The default message passing method is rgcn (Graph convolution layers).\n* Using multiple gcn helps in incorporating all the graph complexity properly and thus creates a better model.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}